{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_AQLhsKQh_N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-fTfc7BvCOz"
      },
      "source": [
        "# 한국어 전처리 패키지 (Text preprocessing Tools for Korean Text)\n",
        "\n",
        "1.PyKoSpacing\n",
        "\n",
        "전희원님이 개발한 PyKoSpacing은 한국어 띄어쓰기 패키지로 띄어쓰기가 되어있지 않은 문장을 띄어쓰기를 한 문장으로 변환해주는 패키지입니다. PyKoSpacing은 대용량 코퍼스를 학습하여 만들어진 띄어쓰기 딥 러닝 모델로 준수한 성능을 가지고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zA0_dBgruBnn",
        "outputId": "d0675c5d-455e-4bd9-a295-3991d8672b1a"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-khj89d5q\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-khj89d5q\n",
            "Collecting tensorflow==2.7.2\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.2%2Bzzzcolab20220516114640-cp37-cp37m-linux_x86_64.whl (671.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 671.4 MB 1.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (3.1.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.47.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (14.0.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.2.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (4.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.2.0)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2268638 sha256=4f1ca3c530e8cc9952956e6261a540610d554082b8a7a66481cb9ce983cc5322\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-isiu6mto/wheels/9b/93/81/a2a7dc8c66ede5bf30634d20635f32b95eac7ca2ea8844058b\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow, argparse, pykospacing\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed argparse-1.4.0 gast-0.4.0 keras-2.7.0 pykospacing-0.5 tensorflow-2.7.2+zzzcolab20220516114640 tensorflow-estimator-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XuxT4OsuBrO"
      },
      "source": [
        "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYiLlotnuBug",
        "outputId": "566bab08-a9f4-4304-aa03-7b2ee6d9a2bd"
      },
      "source": [
        "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
        "print(new_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "S9Ew0FGtuB0f",
        "outputId": "a1d78520-f8d0-492f-c3f5-cb3ff62a2447"
      },
      "source": [
        "#원 문장과 비교\n",
        "\n",
        "from pykospacing import spacing\n",
        "\n",
        "kospacing_sent = spacing(new_sent)\n",
        "print(sent)\n",
        "print(kospacing_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3ac5a844ca35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#원 문장과 비교\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkospacing_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'spacing' from 'pykospacing' (/usr/local/lib/python3.7/dist-packages/pykospacing/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkxcbOzLvW2E"
      },
      "source": [
        "2. Py-Hanspell\n",
        "- Py-Hanspell은 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUTVc4T4uB4g",
        "outputId": "0126272b-796c-4945-d892-bd9755bfbf2e"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-mmzln4mu\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-mmzln4mu\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4868 sha256=e2413eae8a42ce2c84a96c574e790202be61954c430f076372fa84b6eacdc327\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8j9jzl7b/wheels/ab/f5/7b/d4124bb329c905301baed80e2ae45aa14e824f62ebc3ec2cc4\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doE5IVV4veCB",
        "outputId": "0f0a59d7-58fe-4750-83a5-d26bbce362a5"
      },
      "source": [
        "from hanspell import spell_checker\n",
        "\n",
        "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지 \"\n",
        "spelled_sent = spell_checker.check(sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJl7RuexvhJR",
        "outputId": "6b5714a9-890b-498d-bc27-b6002dc537af"
      },
      "source": [
        "spelled_sent = spell_checker.check(new_sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)\n",
        "# print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는 극 중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연제(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-5-dJiuvfoa"
      },
      "source": [
        "이 패키지는 띄어쓰기 또한 보정합니다. PyKoSpacing에 사용한 예제를 그대로 사용해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2HMqvFqvv-R",
        "outputId": "34349f87-8d34-413f-902a-1ac72ab9bac2"
      },
      "source": [
        "spelled_sent = spell_checker.check(new_sent)\n",
        "\n",
        "hanspell_sent = spelled_sent.checked\n",
        "print(hanspell_sent)\n",
        "# print(kospacing_sent) # 앞서 사용한 kospacing 패키지에서 얻은 결과"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는 극 중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연제(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98XDII5Jzw8V"
      },
      "source": [
        "# SOYNLP를 이용한 단어 토큰화\n",
        "\n",
        "soynlp는 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저입니다. 비지도 학습으로 단어 토큰화를 한다는 특징을 갖고 있으며, 데이터에 자주 등장하는 단어들을 단어로 분석합니다. soynlp 단어 토크나이저는 내부적으로 단어 점수 표로 동작합니다. 이 점수는 응집 확률(cohesion probability)과 브랜칭 엔트로피(branching entropy)를 활용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs-oCl6Sz19M",
        "outputId": "515b6b7a-c5cf-4e52-8c64-016282d61ed3"
      },
      "source": [
        "!pip install soynlp\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: soynlp in /usr/local/lib/python3.7/dist-packages (0.0.493)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.0.2)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 502 kB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 19.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArRICPrm0GPD"
      },
      "source": [
        "1. 신조어 문제\n",
        "\n",
        "soynlp를 소개하기 전에 기존의 형태소 분석기가 가진 문제는 무엇이었는지, SOYNLP가 어떤 점에서 유용한지 정리해봅시다. 기존의 형태소 분석기는 신조어나 형태소 분석기에 등록되지 않은 단어 같은 경우에는 제대로 구분하지 못하는 단점이 있었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfxN9nfl0Jiy",
        "outputId": "0899d2d9-3893-493b-8efc-131fcd42ad49"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "tokenizer = Okt()\n",
        "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZiKWdSO0Lgc"
      },
      "source": [
        "에이비식스는 아이돌의 이름이고, 이대휘는 에이비식스의 멤버이며, 최애돌은 최고로 애정하는 캐릭터라는 뜻이지만 위의 형태소 분석 결과에서는 전부 분리된 결과를 보여줍니다.\n",
        "\n",
        "그렇다면 텍스트 데이터에서 특정 문자 시퀀스가 함께 자주 등장하는 빈도가 높고, 앞 뒤로 조사 또는 완전히 다른 단어가 등장하는 것을 고려해서 해당 문자 시퀀스를 형태소라고 판단하는 단어 토크나이저라면 어떨까요?\n",
        "\n",
        "예를 들어 에이비식스라는 문자열이 자주 연결되어 등장한다면 한 단어라고 판단하고, 또한 에이비식스라는 단어 앞, 뒤에 '최고', '가수', '실력'과 같은 독립된 다른 단어들이 계속해서 등장한다면 에이비식스를 한 단어로 파악하는 식이지요. 그리고 이런 아이디어를 가진 단어 토크나이저가 soynlp입니다.\n",
        "\n",
        "\n",
        "2. 학습하기\n",
        "\n",
        "soynlp는 기본적으로 학습에 기반한 토크나이저이므로 학습에 필요한 한국어 문서를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozzTo7h00K_T"
      },
      "source": [
        "import urllib.request\n",
        "from soynlp import DoublespaceLineCorpus\n",
        "from soynlp.word import WordExtractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1DZw3At0XG5",
        "outputId": "165b2d5d-fb2a-4a8e-9349-801991da6a29"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2016-10-20.txt', <http.client.HTTPMessage at 0x7f08c3cd5190>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX_FhooW0SLV",
        "outputId": "f99e65cf-b4a2-40cf-cd96-bfee028227a1"
      },
      "source": [
        "# 훈련 데이터를 다수의 문서로 분리\n",
        "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
        "len(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30091"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKv814Vf0bs-",
        "outputId": "3921de4c-6ae4-4b4b-e41a-5cf2cbffc31b"
      },
      "source": [
        "i = 0\n",
        "for document in corpus:\n",
        "  if len(document) > 0:\n",
        "    print(document)\n",
        "    i = i+1\n",
        "  if i == 3:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19  1990  52 1 22\n",
            "오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다\n",
            "테헤란 연합뉴스 강훈상 특파원 이용 승객수 기준 세계 최대 공항인 아랍에미리트 두바이국제공항은 19일 현지시간 이 공항을 이륙하는 모든 항공기의 탑승객은 삼성전자의 갤럭시노트7을 휴대하면 안 된다고 밝혔다  두바이국제공항은 여러 항공 관련 기구의 권고에 따라 안전성에 우려가 있는 스마트폰 갤럭시노트7을 휴대하고 비행기를 타면 안 된다 며 탑승 전 검색 중 발견되면 압수할 계획 이라고 발표했다  공항 측은 갤럭시노트7의 배터리가 폭발 우려가 제기된 만큼 이 제품을 갖고 공항 안으로 들어오지 말라고 이용객에 당부했다  이런 조치는 두바이국제공항 뿐 아니라 신공항인 두바이월드센터에도 적용된다  배터리 폭발문제로 회수된 갤럭시노트7 연합뉴스자료사진\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLNlJfkO0gI9",
        "outputId": "42a152ac-c1a3-41cf-e097-6d5aeb003540"
      },
      "source": [
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training was done. used memory 1.782 Gb\n",
            "all cohesion probabilities was computed. # words = 223348\n",
            "all branching entropies was computed # words = 361598\n",
            "all accessor variety was computed # words = 361598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tenps97U0eSi"
      },
      "source": [
        "정상 출력되는 것을 확인하였습니다. soynlp는 학습 기반의 단어 토크나이저이므로 기존의 KoNLPy에서 제공하는 형태소 분석기들과는 달리 학습 과정을 거쳐야 합니다. 이는 전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피 단어 점수표를 만드는 과정입니다. WordExtractor.extract()를 통해서 전체 코퍼스에 대해 단어 점수표를 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eOcZRpq5Vdy",
        "outputId": "307c008d-51b0-4651-c841-57f80e63411a"
      },
      "source": [
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training was done. used memory 1.843 Gb\n",
            "all cohesion probabilities was computed. # words = 223348\n",
            "all branching entropies was computed # words = 361598\n",
            "all accessor variety was computed # words = 361598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXAaTvPR5Zvn"
      },
      "source": [
        "# SOYNLP의 응집 확률(cohesion probability)\n",
        "\n",
        "응집 확률은 내부 문자열(substring)이 얼마나 응집하여 자주 등장하는지를 판단하는 척도입니다. 응집 확률은 문자열을 문자 단위로 분리하여 내부 문자열을 만드는 과정에서 왼쪽부터 순서대로 문자를 추가하면서 각 문자열이 주어졌을 때 그 다음 문자가 나올 확률을 계산하여 누적곱을 한 값입니다. 이 값이 높을수록 전체 코퍼스에서 이 문자열 시퀀스는 하나의 단어로 등장할 가능성이 높습니다. 수식은 아래와 같습니다.\n",
        "\n",
        "<figure>\n",
        "<img src = 'https://wikidocs.net/images/page/92961/%EC%88%98%EC%8B%9D.png'>\n",
        "<figure>\n",
        "\n",
        "'반포한강공원에'라는 7의 길이를 가진 문자 시퀀스에 대해서 각 내부 문자열의 스코어를 구하는 과정은 아래와 같습니다.\n",
        "\n",
        "<figure>\n",
        "<img src = 'https://wikidocs.net/images/page/92961/%EC%88%98%EC%8B%9D2.png'>\n",
        "<figure>\n",
        "\n",
        "실습을 통해 직접 응집 확률을 계산해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI3ldGli5yOL",
        "outputId": "db261684-cfd9-4bd1-dac2-ee9f82fb539e"
      },
      "source": [
        "word_score_table[\"반포한\"].cohesion_forward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08838002913645132"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FJyxKWx51NQ"
      },
      "source": [
        "그렇다면 '반포한강'의 응집 확률은 '반포한'의 응집 확률보다 높을까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tb-LQ5C54Wu",
        "outputId": "39376278-e1e5-4289-c017-7de1aae33a98"
      },
      "source": [
        "word_score_table[\"반포한강\"].cohesion_forward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19841268168224552"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYI4plFD56IZ"
      },
      "source": [
        "'반포한강'은 '반포한'보다 응집 확률이 높습니다. 그렇다면 '반포한강공'은 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d564rhpI58Tx",
        "outputId": "69a947f1-d0ac-4039-9411-2ae3f38e2626"
      },
      "source": [
        "word_score_table[\"반포한강공\"].cohesion_forward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2972877884078849"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh5_y1nh5-ar"
      },
      "source": [
        "역시나 '반포한강'보다 응집 확률이 높습니다. '반포한강공원'은 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJeNLZlN6AOP",
        "outputId": "b062b083-cda7-4713-a52b-ee5f5ff9e380"
      },
      "source": [
        "word_score_table[\"반포한강공원\"].cohesion_forward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37891487632839754"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gySYEHLX6BxT"
      },
      "source": [
        "'반포한강공'보다 응집 확률이 높습니다. 여기다가 조사 '에'를 붙인 '반포한강공원에'는 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhQGhujV6Dp1",
        "outputId": "7a314177-568f-44fa-f823-165f058ebede"
      },
      "source": [
        "word_score_table[\"반포한강공원에\"].cohesion_forward"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33492963377557666"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQMfrAgW6FTB"
      },
      "source": [
        "오히려 '반포한강공원'보다 응집도가 낮아집니다. 결국 결합도는 '반포한강공원'일 때가 가장 높았습니다. 응집도를 통해 판단하기에 하나의 단어로 판단하기에 가장 적합한 문자열은 '반포한강공원'이라고 볼 수 있겠네요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TujL6BDkm5lY"
      },
      "source": [
        "# 언어 모델(Language Model)\n",
        "\n",
        "- 언어 모델(Language Model)이란 단어 시퀀스(문장)에 확률을 할당하는 모델을 말함. 어떤 문장들이 있을 때, 적절한지 사람처럼 판단할 수 있다면, 기계가 자연어 처리를 정말 잘한다고 볼 수 있음 -> 언어 모델이 하는 일\n",
        "\n",
        "- 크게는 통계를 이용한 방법과 인공 신경망을 이용한 방법으로 구분이 가능. 최근 핫한 자연어 처리 신기술인  GPT 나 Bert, Transformer 또한 인공 신경망 모델 기반\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주어진 이전 단어들로부터 다음 단어 예측하기\n",
        "\n",
        "- 확률을 할당하기 위해서 가장 보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는 것이다.\n",
        "\n",
        "- 자연어 처리로 유명한 스탠포드 대학교에서는 언어 모델을 문법(Grammar)이라고 비유한다.\n",
        "\n",
        "\n",
        "### 단어 시퀀스의 확률\n",
        "- 하나의 단어를 w, 단어 시퀀스를 대문자 W라고 한다면, n개의 단어가 등장하는 단어 시퀀스 W의 확률은 다음과 같다. P의 확률\n",
        "\n",
        "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~P(W) = P(w_1, w_2, w_3, \\cdots, w_n)$\n",
        "\n",
        "- 언어 모델이 단어들의 조합이 얼마나 적절한지, 또는 해당 문장이 얼마나 적합한지를 알려주는 일을 하기 때문."
      ],
      "metadata": {
        "id": "FArYmfDwTxGM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLfq4_JK3UDv"
      },
      "source": [
        "-  문장의 확률을 예측하는 일이 왜 필요한가?\n",
        "\n",
        "\n",
        "언어 모델은 문장의 확률을 예측하는 일이다. 그럼 문장의 확률을 예측하는 것이 왜 필요한지 예를 들어보도록 한다. 여기서 대문자 P는 확률을 의미한다.\n",
        "\n",
        " - a. 기계 번역(Machine Translation)\n",
        "  - P(나는 버스를 탔다) > P(나는 버스를 태운다)\n",
        "\n",
        "   : 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단한다.\n",
        "\n",
        " - b. 오타 교정(Spell Correction)\n",
        "\n",
        "    - 선생님이 교실로 부리나케\n",
        "\n",
        "    - P(달려갔다) > P(잘려갔다)\n",
        "\n",
        "    - : 언어 모델은 두 문장을 비교하여 좌측의 문장이 확률이 더 높다고 판단한다.\n",
        "\n",
        " - c. 음성 인식(Speech Recognition)\n",
        "\n",
        "    - P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)\n",
        "\n",
        "    - : 언어 모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단한다.\n",
        "\n",
        " - 언어 모델은 위와 같이 보다 **적절한 문장을 선택하는 일에 확률**을 사용한다.\n",
        "\n",
        "\n",
        "\n",
        "#### 문장의 확률 예측\n",
        "\n",
        "\n",
        "- 하나의 단어(word)를 w라고 하자. 단어의 시퀀스인 전체 문장(sentence)을 대문자 W라고 하자. n개의 w로 구성된 문장 W의 확률은 다음과 같이 표현\n",
        "\n",
        " - ${P(W) = P(w_{1},w_{2},w_{3},w_{4},w_{5}, {\\dots}, w_{n}) = {\\Pi_{i=1}^{n}} P(w_n) }$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 통계적 언어 모델(Statistical Language Model, SLM)\n",
        "- 언어 모델의 전통적인 접근 방법인 통계적 언어 모델."
      ],
      "metadata": {
        "id": "4CH9Shhue7Nw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXjjzD0W6a3Z"
      },
      "source": [
        "### 연쇄 법칙(Chain rule)\n",
        "\n",
        "$~~~~~~P(x_1,x_2,x_3,\\cdots, x_n) = P(x_1)P(x_2|x_1)P(x_3|x_1,x_2) \\dots P(x_n|x_1,\\dots,x_{n-1})$\n",
        "\n",
        "이 조건부 확률을 이용하여 '안녕하세요 저는 딥러능을 공부하고 있습니다.'라는 문장의 확률을 구해보자. \n",
        "\n",
        "$P(안녕하세요~저는~딥러닝을~공부하고~있습니다) = P(안녕하세요)\\times P(저는|안녕하세요)\\times P(딥러닝을|안녕하세요~저는) \\times \\dots P(있습니다.|안녕하세요~저는~딥러닝을 공부하고)$\n",
        "\n",
        "해당 문장의 확률은\n",
        "'안녕하세요'가 나올 확률 X\n",
        "'안녕하세요'가 나오고 '저는'이 나올 확률 X\n",
        "'안녕하세요 저는'이 나오고 '딥러닝을'이 나올확률 X ...X\n",
        "'안녕하세요 저는 딥러닝을 공부하고 있습니다.'나오고 '있습니다'가 나올 확률이다.\n",
        "\n",
        "결론은 문장의 확률을 구하기 위해서 각 단어에 대한 예측 확률들을 곱한다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 카운트 기반의 접근\n",
        "\n",
        "- 문장의 확률을 구하기 위해 각 단어에 대한 예측 확률을 모두 곱한다는 것은 알겠지만, 이전 단어로부터 다음 단어에 대한 확률은 어떻게 구할까? 그것은 바로 카운트에 기반하여 확률을 계싼.\n",
        "\n",
        "'안녕하세요 저는 딥러닝을 공부하고'가 나왔을 때 '있습니다'가 나올 확률을 구해보자.\n",
        "\n",
        "$P(있습니다|안녕하세요~저는~딥러닝을~공부하고) = {\\frac{count(안녕하세요저는딥러닝을공부하고있습니다)}{count(안녕하세요저는딥러닝을공부하고)}}$\n",
        "\n",
        "단순히 학습한 코퍼스 데이터에서 '안녕하세요 저는 딥러닝을 공부하고'가 100번 등장하고, 그 다음에 '있습니다'가 등장한 경우가 30번이라고 한다면 P(있습니다|안녕하세요저는딥러닝을공부하고)는 30%가 된다.\n",
        "\n",
        "\n",
        "#### 카운터 기반의 한계 - 희소 문제(Sparsity Problem)\n",
        "\n",
        "- 기계에서 많은 코퍼스를 훈련시켜서 언어 모델을 통해 현실에서의 확률 분포를 근사하는 것이 언어 모델의 목표이다. 하지만, 카운트 기반으로 접근하려고 한다면 갖고 있는 코퍼스(Corpus) 즉, 다시 말해 기계가 훈련하는 데이터는 정말 방대한 양이다.\n",
        "\n",
        "- 위의 카운트 기반 조건부 확률을 구하는 공식에서 분모에 해당하는 카운트 수가 0이면 확률이 정의될 수 가 없다. 쉽게 말해, 학습 데이터를 통해 카운트가 한 번도 되지 않거나 아주 적게되는 경우 언어를 정확히 모델링하지 못하는 문제가 생긴다.\n",
        "\n",
        "- 이러한 문제를 완화하기 위해 n-gram이나 스무딩 백오프와 같은 여러가지 일반화(Generalization) 기법이 존재한다. 하지만 근본적 해결책은 되지 못하기에, 통계적 언어 모델에서 인공 신경망 언어 모델로 트렌트가 바뀌었다."
      ],
      "metadata": {
        "id": "Hw2ubVnegw41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-gram 언어 모델(N-gram Language Model)\n",
        "\n",
        "- n-gram 또한 카운트 기반 통계적 접근 언어 모델이므로 통계적 언어 모델의 일종이다. 하지만 모든 단어를 고려하는 것이 아니고, 일부 단어만 고려하는 접근 방법을 사용. 이 때, 일부 단어를 몇개 보느냐를 결정하는데 이것이 N-gram의 N을 의미한다.\n",
        "\n",
        "###  코퍼스에서 카운트하지 못하는 경우를 감소\n",
        "SLM의 한계는 훈련 코퍼스에 확률을 계산하고 싶은 문장이나 단어가 없을 수 있다는 점이다. 또한 문장이 길어질수록 갖고있는 코퍼스에서 그 문장이 존재하지 않을(카운트할 수 없을) 가능성이 높다. 그런데 다음과 같이 참고하는 단어들을 줄이면 카운트를 할 수 있을 가능성이 높일 수 있다.\n",
        "\n",
        "가령, An adorable little boy가 나왔을 때 is가 나올 확률을 그냥 boy가 나왔을 때 is가 나올 확률로 생각해보는 건 어떨까? 갖고있는 코퍼스에 An adorable little boy is가 있을 가능성 보다는 boy is라는 더 짧은 단어 시퀀스가 존재할 가능성이 더 높다.\n",
        "\n",
        "즉, 앞에서는 An adorable little boy가 나왔을 때 is가 나올 확률을 구하기 위해서는 An adorable little boy가 나온 횟수와 An adorable little boy is가 나온 횟수를 카운트해야만 했지만, 이제는 단어의 확률을 구하고자 기준 단어의 앞 단어를 전부 포함해서 카운트하는 것이 아니라, 앞 단어 중 임의의 개수만 포함해서 카운트하여 근사하자는 것이다. 이렇게 하면 갖고 있는 코퍼스에서 해당 단어의 시퀀스를 카운트할 확률이 높아집니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "예를 들어 '안녕하세요 저는 딥러닝을 공부하고 있습니다.' 라는 문장에 대해 n-gram을 전부 구해보면 아래와 같다.\n",
        "\n",
        "unigrams : 안녕하세요 / 저는 / 딥러닝을 / 공부하고 / 있습니다.\n",
        "bigrams : 안녕하세요 저는 / 저는 딥러닝을 / 딥러닝을 공부하고 / 공부하고 있습니다.\n",
        "trigrams : 안녕하세요 저는 딥러닝을 / 저는 딥러닝을 공부하고 / 딥러닝을 공부하고 있습니다.\n",
        "4-grams : 안녕하세요 저는 딥러닝을 공부하고 / 저는 딥러닝을 공부하고 있습니다.\n",
        "\n",
        "n-gram을 통한 언어 모델에서는 다음에 나올 단어의 예측은 오직 n-1개의 단어에만 의존한다. 예를 들어 '안녕하세요 저는 딥러닝을 공부하고' 다음에 나올 단어를 예측하고 싶다고 할 때, n=3 라고 한 3-gram을 이용한 언어 모델을 사용한다고 합시다. 이 경우, 공부하고 다음에 올 단어를 예측하는 것은 다른 부분은 제외한 n-1에 해당되는 앞의 2개의 단어(예제에서 '딥러닝을 공부하고')만을 고려합니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 유니그램 모형\n",
        "- 만약 모든 단어의 활용이 완전히 서로 독립이라면, 단어 열의 확률은 다음과 같이 각 단어의 확률의 곱이 된다. 이러한 모형을 유니그램 모형이라고 한다.\n",
        "\n",
        "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~P(w_1,w_2,\\cdots,w_m) = \\Pi_{i=1}^m P(w_i)$\n",
        "\n",
        "## 바이그램 모형\n",
        "- 만약 단어의 활용이 바로 전 단어에만 의존한다면 단어 열의 확률은 다음과 같다. 이러한 모형을 바이그램 모형 또는 마코프 모형(markov model)이라고 한다.\n",
        "\n",
        "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~P(w_1,w_2,\\cdots,w_m) = P(w_1) \\Pi_{i=2}^m P(w_i {\\mid} w_{i-1})$\n",
        "\n",
        "## N-gram 모형\n",
        "\n",
        "- 만약 단어의 활용이 바로 전 $n-1$개의 단어에만 의존한다면 단어 열의 확률은 다음과 같다. 이러한 모형을 N그램 모형이라고 한다.\n",
        "\n",
        "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~P(w_1,w_2,\\cdots,w_m) = P(w_1) \\Pi_{i=n}^m P(w_i {\\mid} w_{i-1}, \\cdots,w_{i-n})$"
      ],
      "metadata": {
        "id": "-yVsc_3vgv5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-gram의 한계\n",
        "예를 들어서 '골목에서 담배를 피던 소녀가 나를 쳐다봐서 [ ].' 라는 문장의 마지막에 들어갈 단어를 정하는데, 4-gram 이라 가정한다면 소녀가 나를 쳐다봐서 '설레였다' 라는 문장이 카운트가 많이 되서 결정 될 수 있다는 점이다. 근처 단어 몇 개만 고려하니, 문장 앞쪽의 '골목에서 담배를 피던'이란 수식어가 반영이 되지 않아 '무서웠다'와 같이 의도하고 싶은 대로 문장을 끝맺음하지 못하는 경우가 생긴다는 점이다. 뿐만아니라 여전히 카운트를 기반으로 하기때문에 희소 문제가 존재한다.\n",
        "\n",
        "➕ n 을 선택하는 것은 trade-off 문제\n",
        "trade-off 란, 질과 량 가운데 어느 한편을 늘리면 다른 한편은 그 만큼 줄어드는 것을 이르는 말이다.\n",
        "혹시나 나처럼 trade-off의 뜻을 모르는 분들을 위해 적어둔다.\n",
        "\n",
        "n을 크게하면 실제 훈련 코퍼스에서 해당 n-gram을 카운트할 수 있는 확률은 적어지므로 희소 문제는 점점 심각해지고, 모델 사이즈가 커진다는 문제점도 있다. 기본적으로 코퍼스의 모든 n-gram에 대해서 카운트를 해야 하기 때문이다.\n",
        "\n",
        "n을 작게 선택하면 훈련 코퍼스에서 카운트는 잘 되겠지만 근사의 정확도는 현실의 확률분포와 멀어진다. 그렇기 때문에 적절한 n을 선택해야 합니다. 앞서 언급한 trade-off 문제로 인해 정확도를 높이려면 n은 최대 5를 넘게 잡아서는 안 된다고 권장되고 있다.\n",
        "\n",
        "그래도 n을 1보다는 2로 선택하는 것은 거의 대부분의 경우에서 언어 모델의 성능을 높일 수 있다."
      ],
      "metadata": {
        "id": "fFduTe_Li1TB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSEaDBDYBWyb"
      },
      "source": [
        "# 조건부 확률 추정 방법\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-nMnQUVCFTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ad986c-0ccf-450c-89ce-b79ff319b9fc"
      },
      "source": [
        "from nltk import ConditionalFreqDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "sentence = \"I am a boy a girl a boy.\"\n",
        "sent = []\n",
        "\n",
        "tokens = word_tokenize(sentence)\n",
        "bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\", right_pad_symbol=\"SE\")\n",
        "print(bigram)\n",
        "# print(('a', 'boy') in bigram)\n",
        "print(bigram)\n",
        "# for t in bigram:\n",
        "#   print(t)\n",
        "#   cfd = ConditionalFreqDist(sent.append((t[0],t[1])))\n",
        "\n",
        "cfd = ConditionalFreqDist([(t[0], t[1]) for t in bigram])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<zip object at 0x7f83e4ee4190>\n",
            "<zip object at 0x7f83e4ee4190>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_zip = zip([1,2],[3,4],[5,6])"
      ],
      "metadata": {
        "id": "DWuK31lhS2qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_a=[1, 2, 3, 4]"
      ],
      "metadata": {
        "id": "bNxbxI92Xeiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in temp_zip:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "EVGYcxswW1yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in temp_zip:\n",
        "  print(j)"
      ],
      "metadata": {
        "id": "REsdNKNXTo5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(cfd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cX4yHNHQDA3",
        "outputId": "6d4a2a72-f9bf-46cc-841e-f59f548200dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.probability.ConditionalFreqDist'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tgvbSdFQ-si",
        "outputId": "06cdf03d-7f7e-4c19-c616-fb8370b9c321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SS', 'I'),\n",
              " ('I', 'am'),\n",
              " ('am', 'a'),\n",
              " ('a', 'boy'),\n",
              " ('boy', 'a'),\n",
              " ('a', 'girl'),\n",
              " ('girl', 'a'),\n",
              " ('a', 'boy'),\n",
              " ('boy', '.'),\n",
              " ('.', 'SE')]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgHhYMYYSl6g",
        "outputId": "b00092dc-6629-4b5f-993a-865c40e961d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('boy', 'a'),\n",
              " ('a', 'girl'),\n",
              " ('girl', 'a'),\n",
              " ('a', 'boy'),\n",
              " ('boy', '.'),\n",
              " ('.', 'SE')]"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd.conditions()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IVE017YQPC0Y",
        "outputId": "898508f4-f013-4a3f-d539-41c1a15109ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SS'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNlg3YsxCFbo",
        "outputId": "89ced512-ce40-4a01-c249-65d5b966de69"
      },
      "source": [
        "cfd.conditions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SS', 'I', 'am', 'a', 'boy', 'girl', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrpD6ErXCHMJ",
        "outputId": "dcc51279-473f-45c2-f355-f64253f01a0e"
      },
      "source": [
        "cfd[\"SS\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'I': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfd['a']"
      ],
      "metadata": {
        "id": "Wnb_k0VNnLcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ace0ce9-0943-42ee-a1b4-c2f6feda0a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'boy': 2, 'girl': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMaVUgPfP0JV"
      },
      "source": [
        "다음은 nltk 패키지의 샘플 코퍼스인 movie_reviews의 텍스트로부터 바이그램 확률을 추정하는 예제이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBc_f1lQCIjl",
        "outputId": "2feb492d-66b5-4c71-acdb-03501eea1bdb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "sentences = []\n",
        "for tokens in movie_reviews.sents():\n",
        "    bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\", right_pad_symbol=\"SE\")\n",
        "    sentences += [t for t in bigram]\n",
        "\n",
        "cfd = ConditionalFreqDist([(t[0], t[1]) for t in bigram])\n",
        "sentences[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SS', 'plot'),\n",
              " ('plot', ':'),\n",
              " (':', 'two'),\n",
              " ('two', 'teen'),\n",
              " ('teen', 'couples'),\n",
              " ('couples', 'go'),\n",
              " ('go', 'to'),\n",
              " ('to', 'a'),\n",
              " ('a', 'church'),\n",
              " ('church', 'party'),\n",
              " ('party', ','),\n",
              " (',', 'drink'),\n",
              " ('drink', 'and'),\n",
              " ('and', 'then'),\n",
              " ('then', 'drive'),\n",
              " ('drive', '.'),\n",
              " ('.', 'SE'),\n",
              " ('SS', 'they'),\n",
              " ('they', 'get'),\n",
              " ('get', 'into')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grNPlQEgP1NQ"
      },
      "source": [
        "cfd = ConditionalFreqDist(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa9hFFDxP2Tp",
        "outputId": "d2126b3f-db46-4c55-eb8a-2a0b81a624c4"
      },
      "source": [
        "cfd[\"SS\"].most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 7965), ('it', 3038), ('i', 2350), ('but', 1754), ('he', 1642)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw0a8qtIP3PW",
        "outputId": "ca96a49a-ae0b-4b5d-fa40-471a703f2a3d"
      },
      "source": [
        "cfd[\"i\"].most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"'\", 1357), ('was', 506), ('can', 351), ('have', 330), ('don', 276)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjV4OOG6P9uP",
        "outputId": "908ba52c-adc3-4651-f00f-0a2cd956722d"
      },
      "source": [
        "cfd[\".\"].most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SE', 57626), ('.', 1893), ('\"', 1854), (')', 535), ('s', 129)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한글 폰트 참고 : https://teddylee777.github.io/colab/colab-korean"
      ],
      "metadata": {
        "id": "gZNVBbMJkPPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hb0s6OlkSH8",
        "outputId": "5045678a-9dd9-41ac-8f10-8c0cfaa26a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (8,921 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155685 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "pbddF7e0P-gb",
        "outputId": "a487beb0-fd74-4294-a016-0a9bde10cca5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "plt.subplot(311)\n",
        "cfd[\"SS\"].plot(5, title=\"문장의 첫단어 분포\")\n",
        "plt.subplot(312)\n",
        "cfd[\"i\"].plot(5, title=\"i 다음 단어의 분포\")\n",
        "plt.subplot(313)\n",
        "cfd[\".\"].plot(5, title=\". 다음 단어의 분포\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f83e8370f90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfO8ekONQTOi"
      },
      "source": [
        "빈도를 추정하면 각각의 조건부 확률은 기본적으로 다음과 같이 추정을 할 수 있다.\n",
        "\n",
        "$~~~~~~~~~~~~~~P(w {\\mid} w_c){\\dfrac {C(w_c,w)}{C(w_c)}}$\n",
        "\n",
        "위 식에서 $C(w_c,w)$은 말뭉치에서 $(w_c,w)라는 바이그램이 나타내는 횟수 $C(w_c)$은 전체 말뭉치에서 $(W_c)$ 라는 유니그램(단어)이 나타는 횟수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQCbpS1YQANl"
      },
      "source": [
        "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYvW2gnPSfA4",
        "outputId": "36260313-bd40-4e49-9f6b-2af9bf2fc2e9"
      },
      "source": [
        "cpd[\"i\"].prob(\"am\") # 트레이닝이 끝나면 조건부 확률의 값을 보거나 샘플 문장을 입력해서 문장의 로그 확률을 구할 수 있다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.018562267971650354"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpd[\"i\"].prob(\"'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROKnIIuTutH4",
        "outputId": "2ca70f53-5641-45ad-8dbf-a7b3550ce67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1526605917426032"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2MMnk2nSkT_",
        "outputId": "7f825e61-609e-4952-e8c4-95913e57e231"
      },
      "source": [
        "cpd[\"i\"].prob(\"is\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002249971875351558"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpd[\"i\"].prob(\"are\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA-fnKwEtfgJ",
        "outputId": "ce67610e-d2f8-48e1-9bc9-f31f57482392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001124985937675779"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GPbTO22SlOJ",
        "outputId": "818a9dca-239f-43e1-ba0a-3d955cf13c69"
      },
      "source": [
        "cpd[\"we\"].prob(\"are\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08504504504504505"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDTckpUSmYr",
        "outputId": "df5d1c68-fd54-4048-ca02-125bad5b6039"
      },
      "source": [
        "cpd[\"we\"].prob(\"is\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMhPTsXBSn9s"
      },
      "source": [
        "# 바이그램 언어 모형\n",
        "\n",
        "조건부 확률을 알게 되면 각 문장의 확률을 구할 수 있다.\n",
        "\n",
        "바이그램 모형에서는 전체 문장의 확률은 다음과 같이 조건부 확률을 곱으로 나타냄.\n",
        "\n",
        "$~~~~~~~~~~~~~~~P(SS I am a boy SE) = P(I {\\mid} SS) \t\\cdot P(am {\\mid} I) \t\\cdot P(a {\\mid} am) \t\\cdot P(boy {\\mid} a) \t\\cdot P(am {\\mid} I) \\cdot P(. {\\mid} boy )\\cdot P(SE {\\mid} .)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idHXmwMSSnf2"
      },
      "source": [
        "#문장(단어 리스트)의 리스트를 만듬\n",
        "def sentence_score(s):\n",
        "    p = 0.0\n",
        "    for i in range(len(s) - 1):\n",
        "        c = s[i]\n",
        "        w = s[i + 1]\n",
        "        p += np.log(cpd[c].prob(w) + np.finfo(float).eps)\n",
        "    return np.exp(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wAIWTgpTqhH",
        "outputId": "15634be9-c43a-4384-d67a-85ab64561d34"
      },
      "source": [
        "test_sentence = [\"i\", \"like\", \"the\", \"movie\", \".\"]\n",
        "sentence_score(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.740764134071561e-06"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1XRdtEATr4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6aa3dbb-98d5-494b-8875-6f1ad06e5c72"
      },
      "source": [
        "test_sentence = [\"like\", \"i\", \"the\", \".\", \"movie\"]\n",
        "sentence_score(test_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0530004609775863e-27"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oElPFQpPTs6C"
      },
      "source": [
        "#랜덤하게 문장 생성\n",
        "\n",
        "def generate_sentence(seed=None):\n",
        "    if seed is not None:\n",
        "        import random\n",
        "        random.seed(seed)\n",
        "    c = \"SS\"\n",
        "    sentence = []\n",
        "    while True:\n",
        "        if c not in cpd:\n",
        "            break\n",
        "        w = cpd[c].generate()\n",
        "\n",
        "        if w == \"SE\":\n",
        "            break\n",
        "        elif w in [\"i\", \"ii\", \"iii\"]:\n",
        "            w2 = w.upper()\n",
        "        elif w in [\"mr\", \"luc\", \"i\", \"robin\", \"williams\", \"cindy\", \"crawford\"]:\n",
        "            w2 = w.title()\n",
        "        else:\n",
        "            w2 = w\n",
        "\n",
        "        if c == \"SS\":\n",
        "            sentence.append(w2.title())\n",
        "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
        "            sentence.append(w2)\n",
        "        elif w in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "            sentence.append(w2)\n",
        "        else:\n",
        "            sentence.append(\" \" + w2)\n",
        "\n",
        "        c = w\n",
        "    return \"\".join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkr0bMWJTxSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a3b9fd4-16ea-43ff-b746-146dc9869252"
      },
      "source": [
        "generate_sentence(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Susan egan (or even remotely comprehendible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VxV-qpNT0nF"
      },
      "source": [
        "한글 자료를 이용하여서 Naver Sentiment Moive corpus를 사용해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y3oD60eTy2C",
        "outputId": "bc4393ab-e5cc-444f-ca07-9d05ebdcf42a"
      },
      "source": [
        "%%time\n",
        "!wget -nc -q https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.42 ms, sys: 9.25 ms, total: 13.7 ms\n",
            "Wall time: 220 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT52n6SVT6w4",
        "outputId": "60143a2e-01ee-4868-c6e4-3e83fab1d4b4"
      },
      "source": [
        "#-*-coding : utf-8 -*-\n",
        "import codecs\n",
        "# UTF-8 : '유니코드를 위한 가변 길이(들어오기 전에 비워놓는 길이.) 문자 인코딩 방식 중 하나.\n",
        "#codecs : UTF-8+ 한글처리에 용이.\n",
        "#codecs : 반드시 문자열은 유니코드로 처리 ->어떤 문자열 셋으로 변환된 문자들로 codecs를 통해 열게 된 파일에 쓰는게 안됨.\n",
        "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
        "\n",
        "    # print([line for line in f.read().splitlines()])\n",
        "    data = [line.split('\\t') for line in f.read().splitlines()] #line.split('\\t') :tab키로 분할해주세요.\n",
        "    #f.read().splitlines() :읽었는데, line별로 split로 해준것을 변수로 받아들음.\n",
        "    data = data[1:]   # header 제외\n",
        "    # print(data[1:5])\n",
        "\n",
        "docs = [row[1] for row in data]\n",
        "len(docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbC6ypG3kvpL",
        "outputId": "2357416f-b3a5-40ea-9fca-72ec440ee3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf2K6tt8T8Lk",
        "outputId": "560c7910-14be-4a33-a513-fdcdc78d1265"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "#에러는 아닌데, warning을 무시하겟습니다.\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "tagger = Okt()\n",
        "\n",
        "def tokenize(doc):\n",
        "  # tokens = []\n",
        "  # for t in tagger.pos(doc):\n",
        "  #   print(type(t))\n",
        "  #   tokens.append('/'.join(t))\n",
        "    tokens = ['/'.join(t) for t in tagger.pos(doc)] #Okt의 품사태킹\n",
        "    return tokens\n",
        "\n",
        "tokenize(\"그 영화는 아주 재미있었어요.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['그/Noun', '영화/Noun', '는/Josa', '아주/Noun', '재미있었어요/Adjective', './Punctuation']"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "TwG6Z7fhT9Mw",
        "outputId": "8f417a07-ddcb-4027-87b1-5a97251f30d0"
      },
      "source": [
        "from tqdm import tqdm\n",
        "sentences = []\n",
        "for d in tqdm(docs):\n",
        "    # print('d = ', d)\n",
        "    tokens = tokenize(d)\n",
        "    bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\", right_pad_symbol=\"SE\")\n",
        "    sentences += [t for t in bigram]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 24890/150000 [01:14<06:14, 334.13it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-a4377e63a5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print('d = ', d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_left\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_right\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_pad_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_pad_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbigram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-514fcc7cf750>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#   print(type(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#   tokens.append('/'.join(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Okt의 품사태킹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQRfatnPT-BZ",
        "outputId": "2421d002-fab9-4600-a432-a6e31f2b3738"
      },
      "source": [
        "sentences[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SS', '아/Exclamation'),\n",
              " ('아/Exclamation', '더빙/Noun'),\n",
              " ('더빙/Noun', '../Punctuation'),\n",
              " ('../Punctuation', '진짜/Noun'),\n",
              " ('진짜/Noun', '짜증나네요/Adjective'),\n",
              " ('짜증나네요/Adjective', '목소리/Noun'),\n",
              " ('목소리/Noun', 'SE'),\n",
              " ('SS', '흠/Noun'),\n",
              " ('흠/Noun', '.../Punctuation'),\n",
              " ('.../Punctuation', '포스터/Noun'),\n",
              " ('포스터/Noun', '보고/Noun'),\n",
              " ('보고/Noun', '초딩/Noun'),\n",
              " ('초딩/Noun', '영화/Noun'),\n",
              " ('영화/Noun', '줄/Noun'),\n",
              " ('줄/Noun', '..../Punctuation'),\n",
              " ('..../Punctuation', '오버/Noun'),\n",
              " ('오버/Noun', '연기/Noun'),\n",
              " ('연기/Noun', '조차/Josa'),\n",
              " ('조차/Josa', '가볍지/Adjective'),\n",
              " ('가볍지/Adjective', '않구나/Verb'),\n",
              " ('않구나/Verb', 'SE'),\n",
              " ('SS', '너/Modifier'),\n",
              " ('너/Modifier', '무재/Noun'),\n",
              " ('무재/Noun', '밓었/Noun'),\n",
              " ('밓었/Noun', '다그/Noun'),\n",
              " ('다그/Noun', '래서/Noun'),\n",
              " ('래서/Noun', '보는것을/Verb'),\n",
              " ('보는것을/Verb', '추천/Noun'),\n",
              " ('추천/Noun', '한/Josa'),\n",
              " ('한/Josa', '다/Adverb')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K5xB12pT_LR"
      },
      "source": [
        "cfd = ConditionalFreqDist(sentences)\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
        "\n",
        "def korean_most_common(c, n, pos=None):\n",
        "    if pos is None:\n",
        "        return cfd[tokenize(c)[0]].most_common(n)\n",
        "    else:\n",
        "        return cfd[\"/\".join([c, pos])].most_common(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqfF76A_UANf",
        "outputId": "37fada56-a20d-45ef-ffb2-3e8196c34c3d"
      },
      "source": [
        "korean_most_common(\"나\", 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('는/Josa', 831),\n",
              " ('의/Josa', 339),\n",
              " ('만/Josa', 213),\n",
              " ('에게/Josa', 148),\n",
              " ('에겐/Josa', 84),\n",
              " ('랑/Josa', 81),\n",
              " ('한테/Josa', 50),\n",
              " ('참/Verb', 45),\n",
              " ('이/Determiner', 44),\n",
              " ('와도/Josa', 43)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnOAyLkHUBNh",
        "outputId": "4dff741e-f7d3-4ff5-f061-d2578c9f4a46"
      },
      "source": [
        "korean_most_common(\"의\", 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('영화/Noun', 19),\n",
              " ('연기/Noun', 14),\n",
              " ('구심/Noun', 12),\n",
              " ('모습/Noun', 9),\n",
              " ('감독/Noun', 8),\n",
              " ('매력/Noun', 7),\n",
              " ('감동/Noun', 7),\n",
              " ('흐름/Noun', 6),\n",
              " ('그/Noun', 6),\n",
              " ('이야기/Noun', 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPE8yEUSUCEh",
        "outputId": "f5cfccf8-de7b-42e9-93ed-8335ec584253"
      },
      "source": [
        "korean_most_common(\".\", 10, \"Punctuation\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SE', 26503),\n",
              " ('영화/Noun', 667),\n",
              " ('이/Noun', 565),\n",
              " ('정말/Noun', 480),\n",
              " ('그리고/Conjunction', 455),\n",
              " ('./Punctuation', 445),\n",
              " ('하지만/Conjunction', 369),\n",
              " ('이/Determiner', 352),\n",
              " ('그/Noun', 325),\n",
              " ('스토리/Noun', 317)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jWH5P4nUDP4"
      },
      "source": [
        "def korean_bigram_prob(c, w):\n",
        "    context = tokenize(c)[0]\n",
        "    word = tokenize(w)[0]\n",
        "    return cpd[context].prob(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3JWwB0KUGO7",
        "outputId": "3b0f4d6c-cc8c-40a6-f0a4-07315af247fb"
      },
      "source": [
        "korean_bigram_prob(\"이\", \"영화\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4010748656417948"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcHLWJHOUHDo",
        "outputId": "fa790694-bb2b-4ace-94a4-2521c2dea70f"
      },
      "source": [
        "korean_bigram_prob(\"영화\", \"이\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00015767585785521414"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVBzlgmEUH5k"
      },
      "source": [
        "def korean_generate_sentence(seed=None, debug=False):\n",
        "    if seed is not None:\n",
        "        import random\n",
        "        random.seed(seed)\n",
        "    c = \"SS\"\n",
        "    sentence = []\n",
        "    while True:\n",
        "        if c not in cpd:\n",
        "            break\n",
        "            \n",
        "        w = cpd[c].generate()\n",
        "\n",
        "        if w == \"SE\":\n",
        "            break\n",
        "\n",
        "        w2 = w.split(\"/\")[0]\n",
        "        pos = w.split(\"/\")[1]\n",
        "\n",
        "        if c == \"SS\":\n",
        "            sentence.append(w2.title())\n",
        "        elif c in [\"`\", \"\\\"\", \"'\", \"(\"]:\n",
        "            sentence.append(w2)\n",
        "        elif w2 in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "            sentence.append(w2)\n",
        "        elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
        "            sentence.append(w2)\n",
        "        elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
        "                   \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
        "            sentence.append(w2)\n",
        "        else:\n",
        "            sentence.append(\" \" + w2)\n",
        "        c = w\n",
        "\n",
        "        if debug:\n",
        "            print(w)\n",
        "\n",
        "    return \"\".join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5O7sunBvUJz0",
        "outputId": "2bb8604a-5945-497e-9d5a-95d94cd1b5b7"
      },
      "source": [
        "korean_generate_sentence(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'미키짱과 말도 전혀 빗나가지 않던 전개로 꽥꽥대는거 보니까 요^^'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IenWNd3TUKzq",
        "outputId": "0b00d31a-6777-44d1-8c3e-ea6429c374e2"
      },
      "source": [
        "korean_generate_sentence(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'내용 일테인데 이 영화 최고의 암살 할려고 한 데 선배랑 김선아 연기도 크다. 배슬기 여배우도 있는 척 하는거지?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Nwo4d0phUMS2",
        "outputId": "1076fdb4-9f88-485b-9c77-d6aac481f29a"
      },
      "source": [
        "korean_generate_sentence(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 합성 한 가수 노래와 흥행 놓친 영화다. 사투리 연기 하나 없는 ‘ 스피드 감 넘치는 스릴 넘치는 연기를 이해 되지 못 하시는 분보다 훨 재밌구만 평점을 망처 놓은 듯하다. 영화 보는이로 하여금 불편함을 느꼇을듯'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oeQnXiHzWoG_",
        "outputId": "e8e09ae8-a07f-4169-8dbc-72bbab16ba14"
      },
      "source": [
        "korean_generate_sentence(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'내 인생을 반헬싱이 너무 무섭고 재밌고, 칼 세이건으로 연탄가스 맡아서 죽을 같이 작업 하는구나 ㅋㅋㅋㅋㅋ 진짜'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xJfH98KLWpEU",
        "outputId": "b203e62b-ed1e-4cae-fdf6-31693326e5e0"
      },
      "source": [
        "korean_generate_sentence(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'좋았어요... ㅎㄷㄷㄷ 시나리오나 그래픽이 대단한 심리전이 미라 파스틱 함.. 너무 무섭고 나쁜세 끼는 듯 진짜 꼭 필요가 있는지도 모르겠지만 나름 그의 복수 후!!!!!!!!!!!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loCd9YaEWrNI"
      },
      "source": [
        "확률론적 언어 모형의 활용¶\n",
        "확률론적 언어 모형은 다음과 같은 분야에 광범위하게 활용할 수 있다.\n",
        "\n",
        "- 철자 및 문법 교정(Spell Correction)\n",
        "\n",
        "- 음성 인식(Speech Recognition)\n",
        "\n",
        "- 자동 번역(Machine Translation)\n",
        "\n",
        "- 자동 요약(Summarization)\n",
        "\n",
        "- 챗봇(Question-Answering)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4gBvonW3AD"
      },
      "source": [
        "### N-gram Language Model의 한계\n",
        "1. 희소 문제(sparsity problem)\n",
        "2. n을 선택하는 것은 trade-off 문제\n",
        "-  trade-off 문제로 인해 정확도를 높이려면 n은 최대 5를 넘게 잡아서는 안 된다고 권장되고 있습니다.\n",
        "\n",
        "\n",
        "### 적용 분야(domain)에 맞는 코퍼스의 수집\n",
        "\n",
        "### 인공 신경망을 이용한 언어 모델(Neural Network Based Language Model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VYr2t-nYpqJ"
      },
      "source": [
        "# 언어 모델 평가\n",
        "\n",
        "## Perplexity\n",
        "\n",
        "- 두 개의 모델 A, B가 있을 때 이 모델의 성능은 어떻게 비교할 수 있을까요? 두 개의 모델을 오타 교정, 기계 번역 등의 평가에 투입해볼 수 있겠습니다. 그리고 두 모델이 해당 업무의 성능을 누가 더 잘했는지를 비교하면 되겠습니다.\n",
        "\n",
        "- 이러한 평가를 외부 평가(extrinsic evaluation)라고 하는데, 이러한 평가보다는 어쩌면 조금은 부정확할 수는 있어도 테스트 데이터에 대해서 빠르게 식으로 계산되는 더 간단한 평가 방법이 있습니다. 바로 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 내부 평가(Intrinsic evaluation)에 해당되는 펄플렉서티(perplexity)입니다.\n",
        "\n",
        "- 펄플렉서티(perplexity)는 언어 모델을 평가하기 위한 내부 평가 지표입니다. 보통 줄여서 PPL이 라고 표현합니다\n",
        "\n",
        "- 영어에서 'perplexed'는 '헷갈리는'과 유사한 의미를 가집니다. 그러니까 여기서 PPL은 '헷갈리는 정도'로 이해합시다. PPL를 처음 배울때 다소 낯설게 느껴질 수 있는 점이 있다면, PPL은 수치가 높으면 좋은 성능을 의미하는 것이 아니라, '낮을수록' 언어 모델의 성능이 좋다는 것을 의미한다는 점입니다.\n",
        "\n",
        "- PPL은 단어의 수로 정규화(normalization) 된 테스트 데이터에 대한 확률의 역수입니다. PPL을 최소화한다는 것은 문장의 확률을 최대화하는 것과 같습니다. 문장 $W$의 길이가 $N$이라고 하였을 때의 PPL은 다음과 같습니다.\n",
        "\n",
        "$~~~~~~~~~~~~~~~PPL(W) = P(w_1,w_2,w_3,\\cdots,w_N)^{-{\\dfrac{1}{N}}} =  \\sqrt[\\leftroot{-2}\\uproot{2}N]{{\\dfrac{1}{P(w_1,w_2,w_3,\\cdots,w_N)}}}$\n",
        "\n",
        "\n",
        "문장의 확률에 체인룰(Chain rule)을 적용하면 아래와 같다.\n",
        "$~~~~~~~~~~~~~~~\\sqrt[\\leftroot{-2}\\uproot{2}N]{{\\dfrac{1}{P(w_1,w_2,w_3,\\cdots,w_N)}}} = \\sqrt[\\leftroot{-2}\\uproot{2}N]{{\\dfrac{1}{\\Pi_{i=1}^N P(w_1,w_2,w_3,\\cdots,w_N)}}}$\n",
        "\n",
        "\n",
        "N-gram을 적용하면, ex.bigram\n",
        "\n",
        "$~~~~~~~~~~~~~~~PPL(W) =  \\sqrt[\\leftroot{-2}\\uproot{2}N]{{\\dfrac{1}{\\Pi_{i=1}^N P(w_i {\\mid} {w_{i-1}})}}}$\n",
        "\n",
        "## 분기 계수(Braching Factor)\n",
        "\n",
        "PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 분기계수(branching factor)이다. PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하고 있는지를 의미한다. 어떤 테스트 데이터을 주고 측정했더니 PPL이 10이 나왔다고 해보자.\n",
        "\n",
        "$~~~~~~~~~~~~~~~PPW(W) = P(w_1,w_2,w_3\\cdots,w_N)^{-\\dfrac{1}{N}} = ({{\\dfrac{1}{10}}}^N)^{-\\dfrac{1}{N}} = 10$\n",
        "\n",
        "**같은 테스트 데이터에 대해서** 두 언어 모델의 PPL을 각각 계산 후에 PPL의 값을 비교하면, 두 언어 모델 중 어떤 것이 성능이 좋은지도 판단이 가능합니다.\n",
        "\n",
        "주의할 점은 **PPL의 값이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 것**이지, 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 반드시 의미하진 않는다는 점이다. 또한 언어 모델의 PPL은 테스트 데이터에 의존하므로 두 개 이상의 언어 모델을 비교할 때는 정량적으로 양이 많고, 또한 도메인에 알맞은 동일한 테스트 데이터를 사용해야 신뢰도가 높다는 것이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다양한 단어의 표현 방법\n",
        "## 단어의 표현 방법\n",
        "\n",
        "크게 국소 표현(Local Representation) 방법(또는 이산 표현)과 분산 표현(Distributed Representation) 방법(또는 연속 표현)으로 나뉜다.\n",
        "\n",
        "1. 국소 표현(Local Representation) 또는 이산 표현(Discrete Representation)\n",
        " - 특징 : 해당 단어 그 자체만 보고, 특정값을 매핑하여 단어를 표현하는 방법\n",
        "ex) 강아지, 고양이, 친칠라 라는 단어가 있을 때 각 단어에 1번, 2번, 3번 등과 같은 숫자를 맵핑(mapping)하여 부여한다.\n",
        " - 종류 : One-Hot Vector, N-gram, count base(Bag of Words) 등\n",
        "2. 분산 표현(Distributed Representation) 또는 연속 표현(Continuous Representation)\n",
        " - 특징 : 그 단어를 표현하고자 주변을 참고하여 단어를 표현하는 방법\n",
        "ex) 강아지라는 단어 근처에 주로 귀여운, 사랑스러운이라는 단어가 자주 등장하므로, 강아지라는 단어는 귀엽운, 사랑스러운 느낌이다라고 단어를 정의한다.\n",
        " - 종류 : prediction base(Word2Vec, FastText), count base(LSA, Glove) 등\n",
        "\n",
        "즉, 국소 표현 방법에서 단어의 의미, 느낌을 표현할 수 없지만, 분산 표현 방법은 단어의 느낌을 표현할 수 있다는 차이가 있다."
      ],
      "metadata": {
        "id": "9UZkj2annFCB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5YmPE1GMg7"
      },
      "source": [
        "# 단어 표현의 카테고리화\n",
        "\n",
        "<figure>\n",
        "<img src = 'https://wikidocs.net/images/page/31767/wordrepresentation.PNG'>\n",
        "<figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## BOW(bag of words)\n",
        "- Bag of Words란 **단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중**하는 텍스트 데이터의 수치화 표현 방법입니다\n",
        "- Bag of words를 직역하면 단어들의 가방.\n",
        "\n",
        "\n",
        "- 갖고있는 어떤 텍스트 문서에 있는 단어들을 가방에다가 전부 넣습니다. 그러고나서 이 가방을 흔들어 단어들을 섞습니다. 만약, 해당 문서 내에서 특정 단어가 N번 등장했다면, 이 가방에는 그 특정 단어가 N개 있게됩니다. 또한 가방을 흔들어서 단어를 섞었기 때문에 더 이상 단어의 순서는 중요하지 않습니다.\n",
        "\n",
        "- BoW를 만드는 과정을 이렇게 두 가지 과정으로 생각해보겠습니다.\n",
        " - (1) 우선, 각 단어에 고유한 정수 인덱스를 부여합니다.\n",
        " - (2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듭니다.\n",
        "\n",
        "한국어 예제를 통해서 BoW에 대해서 이해해보도록 하겠습니다.\n",
        "문서1 : 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\n",
        "\n",
        "위의 문서1에 대해서 BoW를 만들어보도록 하겠습니다. 아래의 코드는 입력된 문서에 대해서 단어 집합(vocaburary)을 만들어 인덱스를 할당하고, BoW를 만드는 코드입니다. 이 코드에 이번에 입력할 입력은 문서1입니다.\n",
        "\n",
        "## 장점\n",
        "- 쉽게 빠른 구축\n",
        "- 예상보다 문서의 특징을 잘 나타내어 전통적으로 여러분야에서 활용도가 높음\n",
        "\n",
        "## 단점\n",
        "- 문맥 의미(Semantic Context) 반영 문제\n",
        "- 희소 행렬 문제\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gb2BS3U1nXc5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUoHwyZwWqIM",
        "outputId": "b5da5aef-3bcd-4bdd-f479-47b24c519cd8"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re  \n",
        "okt=Okt()  \n",
        "\n",
        "token=re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")  \n",
        "# 정규 표현식을 통해 온점을 제거하는 정제 작업입니다.  \n",
        "token=okt.morphs(token)  \n",
        "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에다가 넣습니다.  \n",
        "\n",
        "word2index={} # dict\n",
        "bow=[] #bag (공간을 미리 만들어놈.)  \n",
        "for voca in token:  \n",
        "         if voca not in word2index.keys():  #dict의 키가 없다면,\n",
        "             word2index[voca]=len(word2index)  \n",
        "# token을 읽으면서, word2index에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다.   \n",
        "             bow.insert(len(word2index)-1,1)\n",
        "# BoW 전체에 전부 기본값 1을 넣어줍니다. 단어의 개수는 최소 1개 이상이기 때문입니다.  \n",
        "         else:\n",
        "            index=word2index.get(voca)\n",
        "# 재등장하는 단어의 인덱스를 받아옵니다.\n",
        "            bow[index]=bow[index]+1\n",
        "# 재등장한 단어는 해당하는 인덱스의 위치에 1을 더해줍니다. (단어의 개수를 세는 것입니다.)  \n",
        "print(word2index)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LALPk1URIvzJ",
        "outputId": "00f8ebd3-7b74-4f92-de19-0371c672f8e3"
      },
      "source": [
        "bow  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFkfcjjLs9XP",
        "outputId": "b7dd1a79-f3e0-48f0-fbc4-6845abef2ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에서 Mecab설치\n",
        "!pip install konlpy # 한국어 형태소 분석기 패키지 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git # 해당 git에서 Google-Colab git clone하기\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hatHLb9NsoZg",
        "outputId": "fd3db75f-66bc-4677-8eda-14149152c02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 11.12 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-09-07 06:59:21--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNELGRQGWH&Signature=cTPsE9%2FxYjfAvnsxk%2FU8swG7cmM%3D&x-amz-security-token=FwoGZXIvYXdzEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDIfbqAeAhUXX191LwSK%2BAbKZjbZpRYTQou4UXKK7%2F8yxtU5iXhd04x4fztOiecbkzcogDOJfgC3fRF%2F7Ft%2FN4SmUavKRLg2abBkHzLdhgAmafkzYwkB9edWDv1jo5KyJUXrqEuEJvYq1LU5Fgu4i8zawzWJrrAuWAvq4c0eKKFNwwUV5SLnbtttIUR3Wsw0IW4b30GYuF3S6fXM3JvghkSTagTwY1qS9%2BIODpLWk%2FQavuiKV%2F%2B4Ov%2FIl0pXhv6vRrh2sLHOfzpYSyt935Koo6YHhmAYyLcLda0X9olwCFKZZ8poGFZYxkssov86rcuD%2BPFx0IasWsO4EBIMYNs9TjgeM4A%3D%3D&Expires=1662535665 [following]\n",
            "--2022-09-07 06:59:21--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNELGRQGWH&Signature=cTPsE9%2FxYjfAvnsxk%2FU8swG7cmM%3D&x-amz-security-token=FwoGZXIvYXdzEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDIfbqAeAhUXX191LwSK%2BAbKZjbZpRYTQou4UXKK7%2F8yxtU5iXhd04x4fztOiecbkzcogDOJfgC3fRF%2F7Ft%2FN4SmUavKRLg2abBkHzLdhgAmafkzYwkB9edWDv1jo5KyJUXrqEuEJvYq1LU5Fgu4i8zawzWJrrAuWAvq4c0eKKFNwwUV5SLnbtttIUR3Wsw0IW4b30GYuF3S6fXM3JvghkSTagTwY1qS9%2BIODpLWk%2FQavuiKV%2F%2B4Ov%2FIl0pXhv6vRrh2sLHOfzpYSyt935Koo6YHhmAYyLcLda0X9olwCFKZZ8poGFZYxkssov86rcuD%2BPFx0IasWsO4EBIMYNs9TjgeM4A%3D%3D&Expires=1662535665\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.65.156\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.65.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.62MB/s    in 0.5s    \n",
            "\n",
            "2022-09-07 06:59:22 (2.62 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-09-07 07:00:46--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIRGDINVS&Signature=M2dqUt%2FfQSzEJFYvOQmtQqFCyKM%3D&x-amz-security-token=FwoGZXIvYXdzEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDILDntbX%2FJnCsyWIyyK%2BAd53XUcYTho9hHPwILvnhTfMc1J5fn5NyxWX5SdNx7Oe2AQFbBj5WK4QE78t5Gla%2BKDKfOIBQjwykglfMcz4j33CEi7FmabRkTmBi5EcpgBf2j9o0r%2FtVgZJiWwv%2BwnqBidaczGPdIX9JbFp2BTnedpP%2FXYVUL07EkhFzRayg9iowF%2BOP75VXYgmJUSX%2B8wEtQoE0snV9kj0oILo4ffyDHcMtf8q3ku3UeOikqv4aFNjYKFT2BB9Q35QKDfGNxkotILhmAYyLRkECrmQw42Ua3LuQYcKdECRqZ%2BDCe1oR%2FwqBBe3l%2FJJC4Nhr8AeNmoK7hdXaA%3D%3D&Expires=1662535740 [following]\n",
            "--2022-09-07 07:00:46--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNIRGDINVS&Signature=M2dqUt%2FfQSzEJFYvOQmtQqFCyKM%3D&x-amz-security-token=FwoGZXIvYXdzEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDILDntbX%2FJnCsyWIyyK%2BAd53XUcYTho9hHPwILvnhTfMc1J5fn5NyxWX5SdNx7Oe2AQFbBj5WK4QE78t5Gla%2BKDKfOIBQjwykglfMcz4j33CEi7FmabRkTmBi5EcpgBf2j9o0r%2FtVgZJiWwv%2BwnqBidaczGPdIX9JbFp2BTnedpP%2FXYVUL07EkhFzRayg9iowF%2BOP75VXYgmJUSX%2B8wEtQoE0snV9kj0oILo4ffyDHcMtf8q3ku3UeOikqv4aFNjYKFT2BB9Q35QKDfGNxkotILhmAYyLRkECrmQw42Ua3LuQYcKdECRqZ%2BDCe1oR%2FwqBBe3l%2FJJC4Nhr8AeNmoK7hdXaA%3D%3D&Expires=1662535740\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.168.249\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.168.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  22.1MB/s    in 2.2s    \n",
            "\n",
            "2022-09-07 07:00:49 (22.1 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Mecab\n",
        "okt=Mecab()\n",
        "\n",
        "token=\"내꺼인듯 내꺼아닌 내꺼같은 너란 사람은 참\"\n",
        "token=okt.morphs(token) # 형태소분석\n",
        "word2index={}  # 단어에 인덱스 부여\n",
        "bow=[]    # 빈도수저장\n",
        "\n",
        "\n",
        "# 토큰하나씩 들고온다\n",
        "for voca in token:\n",
        "    # word2index 안에 해당 토큰이 없다면\n",
        "    if voca not in word2index:  \n",
        "        # 인덱스(word2index길이만큼)를 지정해주고\n",
        "        word2index[voca]=len(word2index)\n",
        "        # 단어가 등장했으니, 빈도수를 담는 리스트에 1을 넣어준다.\n",
        "        bow.insert(len(word2index)-1,1)\n",
        "    # word2index 안에 있는 토큰이라면\n",
        "    else:\n",
        "        # 해당 토큰의 인덱스를 가져와서\n",
        "        index=word2index[voca]\n",
        "        # 한 번 더나왔으니 그 토큰의 인덱스로 빈도수 리스트에 접근하여 값을 1을 더해준다\n",
        "        bow[index]=bow[index]+1"
      ],
      "metadata": {
        "id": "ryfT8MtWnv1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "50d63c7e-4707-4990-81db-89d3b79db51d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dicpath)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-d %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdicpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/data/tagset/mecab.json'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -d /usr/local/lib/mecab/dic/mecab-ko-dic\n[ifs] no such file or directory: /usr/local/etc/mecabrc\n----------------------------------------------------------\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b2eaec8279a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMecab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mokt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMecab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"내꺼인듯 내꺼아닌 내꺼같은 너란 사람은 참\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dicpath)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/data/tagset/mecab.json'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The MeCab dictionary does not exist at \"%s\". Is the dictionary correctly installed?\\nYou can also try entering the dictionary path when initializing the Mecab class: \"Mecab(\\'/some/dic/path\\')\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdicpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Install MeCab in order to use it: http://konlpy.org/en/latest/install/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: The MeCab dictionary does not exist at \"/usr/local/lib/mecab/dic/mecab-ko-dic\". Is the dictionary correctly installed?\nYou can also try entering the dictionary path when initializing the Mecab class: \"Mecab('/some/dic/path')\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwPYq9_-n0Co",
        "outputId": "dfaa2ed3-f150-4540-9fe1-d63e63caedc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'내꺼': 0, '인듯': 1, '아닌': 2, '같은': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UivsLdEfn38I",
        "outputId": "7951a1ce-83d8-4499-8a66-4de1543ee30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "내꺼라는 단어가 두번 나와서 2라고 적혔고, 나머지는 1번 나와서 위와 같은 결과가 나왔다.\n",
        "\n",
        "즉, 각 token(중복없이)에 인덱스를 부여하고, 해당 token의 빈도수를 기록한 것을 bag에 담아놓는다. 이렇게 bow화된 bag을 이용하여 이후에 어떤 문장이 주어지면, 그 문장을 token화 한 뒤, bag에서 해당 token의 빈도수를 가져와 위 예시의 bow와 같이 단어를 정수화 된 리스트로 만들 수 있다"
      ],
      "metadata": {
        "id": "ifvYa_ocn56c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC-Qd7iRoJ_b"
      },
      "source": [
        "# CountVectorizer 클래스로 BOW 만들기\n",
        "- 사이킷 런에서는 단어의 빈도를 Count하여 Vector로 만드는 CountVectorizer 클래스를 지원합니다. 이를 이용하면 영어에 대해서는 손쉽게 BoW를 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V330lrkIxBV",
        "outputId": "cb4a042c-82f0-4574-ebc8-181d85c2b282"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 2 1 2 1]]\n",
            "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DU10n9Ooqh6"
      },
      "source": [
        "- 예제 문장에서 you와 love는 두 번씩 언급되었으므로 각각 인덱스 2와 인덱스 4에서 2의 값을 가지며, 그 외의 값에서는 1의 값을 가지는 것을 볼 수 있습니다. 또한 알파벳 I는 BoW를 만드는 과정에서 사라졌는데, 이는 CountVectorizer가 기본적으로 길이가 2이상인 문자에 대해서만 토큰으로 인식하기 때문입니다. 정제(Cleaning) 챕터에서 언급했듯이, 영어에서는 길이가 짧은 문자를 제거하는 것 또한 전처리 작업으로 고려되기도 합니다.\n",
        "\n",
        "- 주의할 것은 CountVectorizer는 단지 띄어쓰기만을 기준으로 단어를 자르는 낮은 수준의 토큰화를 진행하고 BoW를 만든다는 점입니다. 이는 영어의 경우 띄어쓰기만으로 토큰화가 수행되기 때문에 문제가 없지만 한국어에 CountVectorizer를 적용하면, 조사 등의 이유로 제대로 BoW가 만들어지지 않음을 의미합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['내꺼인듯 내꺼아닌 내꺼같은 너란 사람은 참','아니 왜 한 글 자 는 없 어 지 는 거 지']\n",
        "vector = CountVectorizer()\n",
        "\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCTxtnnYn_RL",
        "outputId": "845c618d-4e93-4db1-8850-898148e02ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1 0]\n",
            " [0 0 0 0 0 1]]\n",
            "{'내꺼인듯': 2, '내꺼아닌': 1, '내꺼같은': 0, '너란': 3, '사람은': 4, '아니': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만 결과에서 보면 내부 로직에 의해 한글자 이하는 포함시키지 않고, 띄어쓰기로 구분하여 하기 때문에 토큰화하기 때문에, 띄어쓰기를 구분자로 한 토큰화된 결과를 인풋으로 넣거나(ex. 내꺼인듯 내꺼 아닌 내꺼 같은 너란 ...), 한국어에 특화된 다른 라이브러리를 이용하면 좋을 것 같다."
      ],
      "metadata": {
        "id": "DIPXr4InoBxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 불용어를 제거한 Bow 만들기\n",
        "\n",
        "- BoW를 사용한다는 것은 그 문서에서 각 단어가 얼마나 자주 등장했는지를 보겠다는 것입니다.\n",
        "\n",
        "1. 사용자가 직접 정의한 불용어 사용"
      ],
      "metadata": {
        "id": "prbgOdypn-ta"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxaEm60GobGL",
        "outputId": "a68dfd32-d070-4a42-917a-e0c41a9d7cb3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzctCXNpFyd"
      },
      "source": [
        "2. CountVectorizer에서 제공하는 자체 불용어 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzR66tlzpCoh",
        "outputId": "9b3e377c-e3ee-4172-80ea-981c68a029b8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1]]\n",
            "{'family': 0, 'important': 1, 'thing': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAJEih2vphH5"
      },
      "source": [
        "3. NLTK에서 지원하는 불용어 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saqs79b3pKc6",
        "outputId": "3f008657-b0af-42ae-b8a0-5330a1d19162"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "sw = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words =sw)\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    }
  ]
}