{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3H-Ac2JxP22M",
        "eP8lc3-KMZAw",
        "v0u_iC1hUTex"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY7caOeLk089"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git \n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh\n",
        "%cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wRq_SSymEB9",
        "outputId": "8fb9b5bf-a04f-4545-d7b3-0d0d0b70deee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 10.16 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-09-13 00:22:27--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHUSXHRNO&Signature=4h9OOrLOrvBa5jMiwPip7Ox2%2BCQ%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDPWPVX2pzW1DpQDkwiK%2BAfzbqbh9uUj6ijg3LKxA0C7%2FaoG8aW4b8d3nNh9A%2FHoo2pvsvXp63hOPezKLilGaRtEe2%2FqYgSjbct6LiUXaGgY12xfcn%2BDmUqd8D2Dc2sOcgJzbJ3Kg57o62%2B3%2BO2c%2FMqxuqElDcHCFfl4Mo5KUH2JaJzBybme%2FNVoIzjJPMXRD073jwf%2Fxyu60Mm3dg1v3zPz2EMR%2FCUXbnKswuNOspJ5pm5wW0m9F9SrLsUuoVfQYomkH%2FhIY7Is18i%2F%2F6rEonpb%2FmAYyLcP6MikMWtd39MyE1tcGKdr2LAH9oQmBXJ7NskOrdIEHGAFLrphUJMIWcg3a9g%3D%3D&Expires=1663029798 [following]\n",
            "--2022-09-13 00:22:27--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNHUSXHRNO&Signature=4h9OOrLOrvBa5jMiwPip7Ox2%2BCQ%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDPWPVX2pzW1DpQDkwiK%2BAfzbqbh9uUj6ijg3LKxA0C7%2FaoG8aW4b8d3nNh9A%2FHoo2pvsvXp63hOPezKLilGaRtEe2%2FqYgSjbct6LiUXaGgY12xfcn%2BDmUqd8D2Dc2sOcgJzbJ3Kg57o62%2B3%2BO2c%2FMqxuqElDcHCFfl4Mo5KUH2JaJzBybme%2FNVoIzjJPMXRD073jwf%2Fxyu60Mm3dg1v3zPz2EMR%2FCUXbnKswuNOspJ5pm5wW0m9F9SrLsUuoVfQYomkH%2FhIY7Is18i%2F%2F6rEonpb%2FmAYyLcP6MikMWtd39MyE1tcGKdr2LAH9oQmBXJ7NskOrdIEHGAFLrphUJMIWcg3a9g%3D%3D&Expires=1663029798\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.228.97\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.228.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.56MB/s    in 0.2s    \n",
            "\n",
            "2022-09-13 00:22:27 (7.56 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-09-13 00:23:43--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::3403:4be7, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCICXHFMI&Signature=NP3ujSjkWuqe4HWH8L%2BYhUoeH3s%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDBdyM%2FoEDShncejosCK%2BAby8JjJ6ilLbeMoXIBoFxGwyYjWOLx9WI9W%2F2MC0BCxkSox89b9fK922eNCHJNtxvudL6FF8YSTquG8cvO45Hb1n5FyMOQ%2FFx1kZ7V8%2BT8PM6hWd0P0YGaSGl3EEIu6%2F3DXA5jsGCy4epOG1MZefBO1ACogowQ24M1zbFIO8325X7PLM7VZSQBV5W0lWZdvj4fSiwDnkZ%2FasGvNQHKjsfMaq03ppCvJN%2Bl1FzZK06PsgTmdYuW91qUMfq7HIxV4onZr%2FmAYyLRPAGiHfzAGrDwBKjPYYMUF03o%2BZkqcjLP9Y6ydH9FqSdP2bzdURu3BeJCLJXg%3D%3D&Expires=1663030309 [following]\n",
            "--2022-09-13 00:23:43--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCICXHFMI&Signature=NP3ujSjkWuqe4HWH8L%2BYhUoeH3s%3D&x-amz-security-token=FwoGZXIvYXdzEBIaDBdyM%2FoEDShncejosCK%2BAby8JjJ6ilLbeMoXIBoFxGwyYjWOLx9WI9W%2F2MC0BCxkSox89b9fK922eNCHJNtxvudL6FF8YSTquG8cvO45Hb1n5FyMOQ%2FFx1kZ7V8%2BT8PM6hWd0P0YGaSGl3EEIu6%2F3DXA5jsGCy4epOG1MZefBO1ACogowQ24M1zbFIO8325X7PLM7VZSQBV5W0lWZdvj4fSiwDnkZ%2FasGvNQHKjsfMaq03ppCvJN%2Bl1FzZK06PsgTmdYuW91qUMfq7HIxV4onZr%2FmAYyLRPAGiHfzAGrDwBKjPYYMUF03o%2BZkqcjLP9Y6ydH9FqSdP2bzdURu3BeJCLJXg%3D%3D&Expires=1663030309\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.129.201\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.129.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  77.0MB/s    in 0.6s    \n",
            "\n",
            "2022-09-13 00:23:44 (77.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\") # train\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\") # test\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\") # train + test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGQ7KyLSlEYd",
        "outputId": "d99d86c0-ad6e-4223-ae0a-8e741a23fb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings.txt', <http.client.HTTPMessage at 0x7fef89ad89d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')"
      ],
      "metadata": {
        "id": "4LZFzLMPlncc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QQgnDozsl8aK",
        "outputId": "210fb4db-a863-4885-a8cc-d088b815462a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
              "6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
              "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
              "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
              "9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5160b2d-8754-4c01-8b66-5a379d2b196d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5403919</td>\n",
              "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7797314</td>\n",
              "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9443947</td>\n",
              "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7156791</td>\n",
              "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5912145</td>\n",
              "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5160b2d-8754-4c01-8b66-5a379d2b196d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5160b2d-8754-4c01-8b66-5a379d2b196d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5160b2d-8754-4c01-8b66-5a379d2b196d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mecab"
      ],
      "metadata": {
        "id": "3H-Ac2JxP22M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()"
      ],
      "metadata": {
        "id": "taGw2YFAmB96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data, tokenizer):\n",
        "    result = []\n",
        "\n",
        "    for sentence in data:\n",
        "        curr_data = []\n",
        "        curr_data = tokenizer.morphs(sentence) # mecab 형태소 분석 tokenizer\n",
        "        # curr_data = [word for word in curr_data if not word in stopwords] # 불용어 제거\n",
        "        result.append(curr_data)\n",
        "    return result"
      ],
      "metadata": {
        "id": "SHCVNNSsnWqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(train_data, test_data, num_words=10000):\n",
        "\n",
        "    # 중복 제거\n",
        "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "\n",
        "    # Nan 결측치 제거\n",
        "    train_data = train_data.dropna(how='any')\n",
        "    test_data = test_data.dropna(how='any')\n",
        "\n",
        "    # 토큰화 및 불용어 제거\n",
        "    x_train = tokenize(train_data['document'],mecab)\n",
        "    x_test = tokenize(test_data['document'], mecab)\n",
        "\n",
        "    # 단어장 만드는 중...\n",
        "    words = np.concatenate(x_train).tolist()\n",
        "    counter = Counter(words)\n",
        "    counter = counter.most_common(10000-4)\n",
        "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
        "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
        "\n",
        "    def wordlist_to_indexlist(wordlist):\n",
        "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
        "    \n",
        "    x_train = list(map(wordlist_to_indexlist, x_train))\n",
        "    x_test = list(map(wordlist_to_indexlist, x_test))\n",
        "\n",
        "    return x_train, np.array(list(train_data['label'])), x_test, np.array(list(test_data['label'])), word_to_index"
      ],
      "metadata": {
        "id": "Xjnat1RvnbDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
      ],
      "metadata": {
        "id": "uKSOjLKqnsDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index:word for word, index in word_to_index.items()}"
      ],
      "metadata": {
        "id": "j5fLTQ5SoQrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수\n",
        "# 단, 모든 문장은 <BOS>로 시작하는 것을 말합니다.\n",
        "\n",
        "def get_encoded_sentence(sentence, word_to_index): ##### 텍스트 -> 숫자\n",
        "    return [word_to_index['<BOS>']] + [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
        "\n",
        "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해주는 함수입니다.\n",
        "def get_encoded_sentences(sentences, word_to_index):\n",
        "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
        "\n",
        "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. ##### 숫자 -> 텍스트\n",
        "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
        "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])\n",
        "\n",
        "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다.\n",
        "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
        "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
      ],
      "metadata": {
        "id": "KCbws2ZYoVv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_decoded_sentence(X_train[5], index_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7bXsHutkoajs",
        "outputId": "c943d826-d933-47a4-c162-6b5c8882d220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<UNK> <UNK> 3 세 부터 초등 학교 1 학년 생 인 8 살 용 영화 . ㅋㅋㅋ . .. 별반 개 도 아까움 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 셋 내 문장 길이 분포\n",
        "total_data_text = list(X_train) + list(X_test)\n",
        "\n",
        "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
        "num_tokens = [len(tokens) for tokens in total_data_text]\n",
        "num_tokens = np.array(num_tokens)\n",
        "\n",
        "# 문장 길이의 평균값, 최대값, 표준편차를 계산\n",
        "print('문장길이 평균 :', np.mean(num_tokens))\n",
        "print('문장길이 최대 :', np.max(num_tokens))\n",
        "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
        "\n",
        "# 예를 들면 최대길이를 (평균 + 2*표준편차)로 한다면,\n",
        "max_tokens = np.mean(num_tokens) +2 * np.std(num_tokens)\n",
        "\n",
        "maxlen = int(max_tokens)\n",
        "print('pad_sequences maxlen : ', maxlen)\n",
        "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens)/len(num_tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_2nRNcos_8",
        "outputId": "671e394e-3d7d-4c62-8c45-bf914b7607a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장길이 평균 : 18.722963668289488\n",
            "문장길이 최대 : 116\n",
            "문장길이 표준편차 :  15.329504488772837\n",
            "pad_sequences maxlen :  49\n",
            "전체 문장의 0.9346725436292804%가 maxlen 설정값 이내에 포함됩니다. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 추가\n",
        "X_train = pad_sequences(X_train, value=word_to_index['<PAD>'], padding='pre', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, value=word_to_index['<PAD>'], padding='pre', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "rd5AABiwozQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ejVmzT4o3k3",
        "outputId": "0708dd9f-a7d1-49b8-b125-0b615058df49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(146182, 49)\n",
            "(49157, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200 # 2의 배수\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so8j0osLo67p",
        "outputId": "aaef1ec1-f5b4-4be4-f2a3-922e50baea8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 200)         2000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 8)                 6688      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,769\n",
            "Trainable params: 2,006,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = X_train[:50000]\n",
        "y_val = y_train[:50000]\n",
        "\n",
        "partial_X_train = X_train[50000:]\n",
        "partial_y_train = y_train[50000:]"
      ],
      "metadata": {
        "id": "VSvFHklFvn-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 얼리스탑\n",
        "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights = True)"
      ],
      "metadata": {
        "id": "xKrE_ujFHfsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "epochs= 100\n",
        "history = model.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJUSn5rMq1wB",
        "outputId": "c69d14a7-67a4-4336-97c1-f8e6581fa644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 [==============================] - 10s 12ms/step - loss: 0.4682 - accuracy: 0.7875 - val_loss: 0.3640 - val_accuracy: 0.8423\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.3309 - accuracy: 0.8609 - val_loss: 0.3430 - val_accuracy: 0.8527\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.2961 - accuracy: 0.8770 - val_loss: 0.3434 - val_accuracy: 0.8531\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.2722 - accuracy: 0.8880 - val_loss: 0.3491 - val_accuracy: 0.8515\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.2501 - accuracy: 0.8971 - val_loss: 0.3513 - val_accuracy: 0.8534\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.2288 - accuracy: 0.9078 - val_loss: 0.3659 - val_accuracy: 0.8534\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.2093 - accuracy: 0.9170 - val_loss: 0.3864 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1915 - accuracy: 0.9247 - val_loss: 0.4051 - val_accuracy: 0.8511\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1763 - accuracy: 0.9329 - val_loss: 0.4307 - val_accuracy: 0.8477\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1622 - accuracy: 0.9390 - val_loss: 0.4583 - val_accuracy: 0.8462\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.1477 - accuracy: 0.9454 - val_loss: 0.4804 - val_accuracy: 0.8464\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1436 - accuracy: 0.9475 - val_loss: 0.4869 - val_accuracy: 0.8452\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.1284 - accuracy: 0.9539 - val_loss: 0.5127 - val_accuracy: 0.8435\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.1181 - accuracy: 0.9584 - val_loss: 0.5552 - val_accuracy: 0.8417\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 0.5705 - val_accuracy: 0.8438\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.1004 - accuracy: 0.9653 - val_loss: 0.6041 - val_accuracy: 0.8414\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0959 - accuracy: 0.9674 - val_loss: 0.6010 - val_accuracy: 0.8415\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0913 - accuracy: 0.9687 - val_loss: 0.6415 - val_accuracy: 0.8394\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0832 - accuracy: 0.9722 - val_loss: 0.6777 - val_accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 2s 11ms/step - loss: 0.0764 - accuracy: 0.9744 - val_loss: 0.6887 - val_accuracy: 0.8395\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.0727 - accuracy: 0.9756 - val_loss: 0.7356 - val_accuracy: 0.8373\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0689 - accuracy: 0.9775 - val_loss: 0.7488 - val_accuracy: 0.8376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21tpPpE1w2WN",
        "outputId": "39b2d9c3-0247-4760-de3b-5a2a1f3461d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 4s - loss: 0.3532 - accuracy: 0.8460 - 4s/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BftgGkMw4E2",
        "outputId": "6a348702-f508-42a4-fae6-5c7fa83cab3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35317349433898926, 0.8460239768028259]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentencepiece\n",
        "# 커스텀 함수 선언"
      ],
      "metadata": {
        "id": "cShmIkqtP9jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAj3ORR1xGJ5",
        "outputId": "8ea7ea32-f9f2-41f5-aa5b-7a2845c9f17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import csv"
      ],
      "metadata": {
        "id": "M6Tlcd3RxMfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spm_write_and_tokenize(data, file_name, model = 'bpe', vocab_size = 8000):\n",
        "  corpus = file_name + '.txt'\n",
        "  with open(corpus, 'w', encoding='utf8') as f:\n",
        "    f.write('\\n'.join(data))\n",
        "  \n",
        "  prefix = file_name+'_vocab_'+str(vocab_size)+\"_\"+model\n",
        "  spm.SentencePieceTrainer.Train(\n",
        "      \n",
        "      f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size}\" +\n",
        "      \"--model_type=\" + \"model\" +     # (unigram(default), bpe, char, word)\n",
        "      \"--max_sentence_length=999999\"  #문장 최대 길이\n",
        "  )\n",
        "  result = pd.read_csv(prefix+'.vocab', sep='\\t', header = None,\n",
        "                       quoting=csv.QUOTE_NONE)\n",
        "  \n",
        "  return result\n"
      ],
      "metadata": {
        "id": "dKGGhKgZzxdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sp_tokenize(s, corpus):\n",
        "    \n",
        "    # 텐서를 저장할 리스트 초기화\n",
        "    tensor = []\n",
        "    # 받아온 문장들을 한 문장씩 가져와서\n",
        "    for sen in corpus:\n",
        "      # tensor리스트에 인덱스화를 시킨 채로 append\n",
        "        tensor.append(s.EncodeAsIds(sen))\n",
        "    # 단어장을 불러옴\n",
        "    with open(vocab_name, 'r') as f:\n",
        "        vocab = f.readlines()\n",
        "\n",
        "    word_index = {}\n",
        "    index_word = {}\n",
        "\n",
        "    for idx, line in enumerate(vocab):\n",
        "      # 단어장을 한줄단위로 불러와 탭을 기준으로 split을 한 상태에서 첫번째 인자를 word로 저장\n",
        "        word = line.split(\"\\t\")[0]  \n",
        "      # 딕셔너리 형태로 인덱스:단어, 단어:인덱스 형태로 저장\n",
        "        word_index.update({idx:word})\n",
        "        index_word.update({word:idx})\n",
        "    \n",
        "    # tensor 패딩(앞)을 진행\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre')\n",
        "\n",
        "    return tensor, word_index, index_word"
      ],
      "metadata": {
        "id": "U93_p9ZhERhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_data.drop_duplicates(subset=['document'], inplace=True)"
      ],
      "metadata": {
        "id": "ifFpuIUi6wUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_t = train_data.dropna(how='any')\n",
        "test_data_t = test_data.dropna(how='any')"
      ],
      "metadata": {
        "id": "i6zdLcM363Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vocab_size = 8000    \n",
        "# model_type = bpe"
      ],
      "metadata": {
        "id": "RgrmJdqWNCY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vs = 8000\n",
        "md = 'bpe'\n",
        "result_df = spm_write_and_tokenize(train_data_t['document'], 'naver', model = md, vocab_size=vs)"
      ],
      "metadata": {
        "id": "9G0lC_eW6Tvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "sXE7xuctEg2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "694c2318-639b-4548-95d4-086122176b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0     <unk>   0.00000\n",
              "1       <s>   0.00000\n",
              "2      </s>   0.00000\n",
              "3         ▁  -3.23816\n",
              "4         .  -3.48155\n",
              "...     ...       ...\n",
              "7995      떻 -13.81930\n",
              "7996      렸 -13.81940\n",
              "7997      렇 -13.81950\n",
              "7998      봤 -13.81960\n",
              "7999      탤 -13.81960\n",
              "\n",
              "[8000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7999aac9-e36c-4dda-bf03-f800ec2c19f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>▁</td>\n",
              "      <td>-3.23816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.</td>\n",
              "      <td>-3.48155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>떻</td>\n",
              "      <td>-13.81930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>렸</td>\n",
              "      <td>-13.81940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>렇</td>\n",
              "      <td>-13.81950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>봤</td>\n",
              "      <td>-13.81960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>탤</td>\n",
              "      <td>-13.81960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7999aac9-e36c-4dda-bf03-f800ec2c19f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7999aac9-e36c-4dda-bf03-f800ec2c19f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7999aac9-e36c-4dda-bf03-f800ec2c19f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'naver_vocab_'+str(vs)+'_'+md+'.model'\n",
        "vocab_name = 'naver_vocab_'+str(vs)+'_'+md+'.vocab'\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(model_name)"
      ],
      "metadata": {
        "id": "qLTy2p23E6Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e256f44-3098-487b-fdea-5c737c6634df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor, word_index, index_word = sp_tokenize(sp, train_data_t['document'])\n",
        "tensor_test, word_index_test, index_word_test = sp_tokenize(sp, test_data_t['document'])"
      ],
      "metadata": {
        "id": "QeBoHgOiFJkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)"
      ],
      "metadata": {
        "id": "MeQghPtYFlLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8fab1f-5ba9-4df3-852a-7d4ecc7a8960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 2193   66 1850]\n",
            " [   0    0    0 ... 7039  823  407]\n",
            " [   0    0    0 ... 2266 1658  325]\n",
            " ...\n",
            " [   0    0    0 ... 3790   92   20]\n",
            " [   0    0    0 ...  299  163  135]\n",
            " [   0    0    0 ...  446 5882    7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_test)"
      ],
      "metadata": {
        "id": "HTmLw-f0ypLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9539ffc0-474e-435e-ccd2-16f1d4aa073f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...    0 2855  317]\n",
            " [   0    0    0 ... 4466 4602 1911]\n",
            " [   0    0    0 ...  734 7264 6496]\n",
            " ...\n",
            " [   0    0    0 ... 5555   85 2885]\n",
            " [   0    0    0 ...  345  865   44]\n",
            " [   0    0    0 ...   12  194 4302]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200 # 2의 배수\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PcluwTdAGWo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62018bcb-798d-4026-cf70-1938d7c50d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 200)         2000000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 8)                 6688      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,769\n",
            "Trainable params: 2,006,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_train[:50000]\n",
        "y_tr = y_train[50000:]"
      ],
      "metadata": {
        "id": "ku8QL5sMGcn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = tensor[:50000]\n",
        "X_train = tensor[50000:]"
      ],
      "metadata": {
        "id": "OOybnZnAHD-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "HOnkXd18ERo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9325844a-7fad-4b3c-f2c4-1692c0261116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ..., 3858, 1762,    5],\n",
              "       [   0,    0,    0, ...,    3, 1195,    7],\n",
              "       [   0,    0,    0, ..., 2857, 6133,    4],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 3790,   92,   20],\n",
              "       [   0,    0,    0, ...,  299,  163,  135],\n",
              "       [   0,    0,    0, ...,  446, 5882,    7]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "T6xNDqLUEUV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3455ab44-1b9d-4923-ee83-3761fe92177a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = tensor_test"
      ],
      "metadata": {
        "id": "uz7myyxbANEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Qiigh7cf-nGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad5ec50-96c1-475c-bbcd-6c7a378386d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96182, 134)\n",
            "(146182,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "epochs= 100\n",
        "history = model.fit(X_train, y_tr, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "id": "5KgQRDYyGanm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2029327f-3c53-42c9-99cf-8d3c5726f76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 [==============================] - 8s 28ms/step - loss: 0.4844 - accuracy: 0.7865 - val_loss: 0.3723 - val_accuracy: 0.8434\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.3345 - accuracy: 0.8605 - val_loss: 0.3438 - val_accuracy: 0.8512\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.2930 - accuracy: 0.8799 - val_loss: 0.3403 - val_accuracy: 0.8521\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.2636 - accuracy: 0.8925 - val_loss: 0.3446 - val_accuracy: 0.8508\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2390 - accuracy: 0.9025 - val_loss: 0.3663 - val_accuracy: 0.8487\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2172 - accuracy: 0.9112 - val_loss: 0.3828 - val_accuracy: 0.8471\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1973 - accuracy: 0.9209 - val_loss: 0.4008 - val_accuracy: 0.8435\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 3s 18ms/step - loss: 0.1825 - accuracy: 0.9278 - val_loss: 0.4337 - val_accuracy: 0.8411\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1680 - accuracy: 0.9344 - val_loss: 0.4439 - val_accuracy: 0.8382\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1487 - accuracy: 0.9436 - val_loss: 0.5001 - val_accuracy: 0.8371\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1338 - accuracy: 0.9501 - val_loss: 0.5216 - val_accuracy: 0.8345\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.1212 - accuracy: 0.9564 - val_loss: 0.5859 - val_accuracy: 0.8349\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1217 - accuracy: 0.9569 - val_loss: 0.5450 - val_accuracy: 0.8316\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.1073 - accuracy: 0.9629 - val_loss: 0.6003 - val_accuracy: 0.8348\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0876 - accuracy: 0.9716 - val_loss: 0.6713 - val_accuracy: 0.8315\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.7180 - val_accuracy: 0.8285\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0674 - accuracy: 0.9785 - val_loss: 0.7969 - val_accuracy: 0.8282\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.8286 - val_accuracy: 0.8277\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0554 - accuracy: 0.9832 - val_loss: 0.8740 - val_accuracy: 0.8266\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.9264 - val_accuracy: 0.8275\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0436 - accuracy: 0.9869 - val_loss: 0.9738 - val_accuracy: 0.8267\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.9718 - val_accuracy: 0.8249\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0540 - accuracy: 0.9830 - val_loss: 1.0095 - val_accuracy: 0.8241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "vW_2hXMsH2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0254939-61cb-4f57-8a77-c4f8b3443168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 6s - loss: 0.3507 - accuracy: 0.8474 - 6s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "h85nkpgrHJR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf32d98-6232-4522-df47-aaa21715451d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.35067451000213623, 0.8474276065826416]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vocab_size = 5000\n",
        "# model_type = bpe"
      ],
      "metadata": {
        "id": "eP8lc3-KMZAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vs = 5000\n",
        "md = 'bpe'\n",
        "result_df = spm_write_and_tokenize(train_data_t['document'], 'naver', vocab_size = vs, model=md)"
      ],
      "metadata": {
        "id": "iA1CzdxDKcSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'naver_vocab_'+str(vs)+'_'+md+'.model'\n",
        "vocab_name = 'naver_vocab_'+str(vs)+'_'+md+'.vocab'\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3d7858-5afe-47eb-ccf7-f7e06a259c18",
        "id": "OhmuUH5zKcSV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor, word_index, index_word = sp_tokenize(sp, train_data_t['document'])\n",
        "tensor_test, word_index_test, index_word_test = sp_tokenize(sp, test_data_t['document'])"
      ],
      "metadata": {
        "id": "Z-77oP4aKcSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200 # 2의 배수\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8a895c-c8d8-4710-a874-91e8a5692b35",
        "id": "VMY2PfD6KcSV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 200)         2000000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 8)                 6688      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,769\n",
            "Trainable params: 2,006,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_train[:50000]\n",
        "y_tr = y_train[50000:]\n",
        "X_val = tensor[:50000]\n",
        "X_train = tensor[50000:]\n",
        "\n",
        "X_test = tensor_test"
      ],
      "metadata": {
        "id": "5ujdqw2ZKcSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "epochs= 100\n",
        "history = model.fit(X_train, y_tr, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf35bc0-755a-46d9-b01c-27291c54caf5",
        "id": "bH_yTsa5KcSW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 [==============================] - 5s 19ms/step - loss: 0.5064 - accuracy: 0.7659 - val_loss: 0.3805 - val_accuracy: 0.8399\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.3535 - accuracy: 0.8500 - val_loss: 0.3553 - val_accuracy: 0.8482\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.3220 - accuracy: 0.8643 - val_loss: 0.3464 - val_accuracy: 0.8506\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.3010 - accuracy: 0.8731 - val_loss: 0.3506 - val_accuracy: 0.8504\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3596 - val_accuracy: 0.8471\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2681 - accuracy: 0.8894 - val_loss: 0.3601 - val_accuracy: 0.8462\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2513 - accuracy: 0.8976 - val_loss: 0.3709 - val_accuracy: 0.8463\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2374 - accuracy: 0.9048 - val_loss: 0.3778 - val_accuracy: 0.8452\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2216 - accuracy: 0.9118 - val_loss: 0.3903 - val_accuracy: 0.8434\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2064 - accuracy: 0.9194 - val_loss: 0.4092 - val_accuracy: 0.8418\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1940 - accuracy: 0.9255 - val_loss: 0.4406 - val_accuracy: 0.8405\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1872 - accuracy: 0.9281 - val_loss: 0.4476 - val_accuracy: 0.8398\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1787 - accuracy: 0.9315 - val_loss: 0.4712 - val_accuracy: 0.8370\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1609 - accuracy: 0.9408 - val_loss: 0.4878 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1498 - accuracy: 0.9452 - val_loss: 0.5168 - val_accuracy: 0.8310\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1401 - accuracy: 0.9495 - val_loss: 0.5493 - val_accuracy: 0.8302\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1400 - accuracy: 0.9494 - val_loss: 0.5599 - val_accuracy: 0.8316\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1267 - accuracy: 0.9563 - val_loss: 0.5953 - val_accuracy: 0.8283\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1175 - accuracy: 0.9598 - val_loss: 0.6316 - val_accuracy: 0.8269\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1169 - accuracy: 0.9599 - val_loss: 0.6192 - val_accuracy: 0.8294\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1038 - accuracy: 0.9656 - val_loss: 0.6750 - val_accuracy: 0.8240\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0947 - accuracy: 0.9696 - val_loss: 0.7057 - val_accuracy: 0.8244\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0931 - accuracy: 0.9701 - val_loss: 0.7430 - val_accuracy: 0.8249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUKz7oiIKcSX",
        "outputId": "bfa64fcb-daa7-4c48-c63c-edae45531973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 7s - loss: 0.3560 - accuracy: 0.8435 - 7s/epoch - 4ms/step\n",
            "[0.3559766411781311, 0.8435014486312866]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vocab_size = 5000\n",
        "# model_type = unigram"
      ],
      "metadata": {
        "id": "v0u_iC1hUTex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vs = 5000\n",
        "md = 'unigram'\n",
        "result_df = spm_write_and_tokenize(train_data_t['document'], 'naver', vocab_size = vs, model=md)"
      ],
      "metadata": {
        "id": "maMz4MUyUTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'naver_vocab_'+str(vs)+'_'+md+'.model'\n",
        "vocab_name = 'naver_vocab_'+str(vs)+'_'+md+'.vocab'\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHvJxXqvUTe3",
        "outputId": "32bdc8af-090f-4674-ba72-c33e9e36e907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor, word_index, index_word = sp_tokenize(sp, train_data_t['document'])\n",
        "tensor_test, word_index_test, index_word_test = sp_tokenize(sp, test_data_t['document'])"
      ],
      "metadata": {
        "id": "NPNr4A-bUTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "word_vector_dim = 200 # 2의 배수\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(8))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54iYwfL3UTe3",
        "outputId": "b5fb0892-c3d5-4187-a85c-550f2c5cc49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 200)         2000000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 8)                 6688      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,769\n",
            "Trainable params: 2,006,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_train[:50000]\n",
        "y_tr = y_train[50000:]\n",
        "X_val = tensor[:50000]\n",
        "X_train = tensor[50000:]\n",
        "\n",
        "X_test = tensor_test"
      ],
      "metadata": {
        "id": "iUNgqlNTUTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "epochs= 100\n",
        "history = model.fit(X_train, y_tr, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvsy2jUeUTe3",
        "outputId": "65a81f36-55f2-4947-93b1-473ba8eb1097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 [==============================] - 5s 19ms/step - loss: 0.4790 - accuracy: 0.7862 - val_loss: 0.3755 - val_accuracy: 0.8383\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.3513 - accuracy: 0.8501 - val_loss: 0.3522 - val_accuracy: 0.8492\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.3234 - accuracy: 0.8636 - val_loss: 0.3500 - val_accuracy: 0.8503\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.3007 - accuracy: 0.8735 - val_loss: 0.3461 - val_accuracy: 0.8520\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2794 - accuracy: 0.8837 - val_loss: 0.3476 - val_accuracy: 0.8515\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2616 - accuracy: 0.8923 - val_loss: 0.3516 - val_accuracy: 0.8510\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.2441 - accuracy: 0.8993 - val_loss: 0.3677 - val_accuracy: 0.8474\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2283 - accuracy: 0.9071 - val_loss: 0.3727 - val_accuracy: 0.8482\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2129 - accuracy: 0.9147 - val_loss: 0.3945 - val_accuracy: 0.8467\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2019 - accuracy: 0.9198 - val_loss: 0.4131 - val_accuracy: 0.8423\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1901 - accuracy: 0.9257 - val_loss: 0.4219 - val_accuracy: 0.8402\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1772 - accuracy: 0.9321 - val_loss: 0.4437 - val_accuracy: 0.8394\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1642 - accuracy: 0.9376 - val_loss: 0.4753 - val_accuracy: 0.8377\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1522 - accuracy: 0.9435 - val_loss: 0.4992 - val_accuracy: 0.8356\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1439 - accuracy: 0.9470 - val_loss: 0.5185 - val_accuracy: 0.8345\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1343 - accuracy: 0.9519 - val_loss: 0.5543 - val_accuracy: 0.8358\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1239 - accuracy: 0.9567 - val_loss: 0.5863 - val_accuracy: 0.8337\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1218 - accuracy: 0.9572 - val_loss: 0.5995 - val_accuracy: 0.8316\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.1086 - accuracy: 0.9632 - val_loss: 0.6175 - val_accuracy: 0.8297\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0988 - accuracy: 0.9672 - val_loss: 0.6694 - val_accuracy: 0.8281\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0957 - accuracy: 0.9692 - val_loss: 0.6737 - val_accuracy: 0.8293\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0864 - accuracy: 0.9724 - val_loss: 0.7278 - val_accuracy: 0.8265\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0791 - accuracy: 0.9754 - val_loss: 0.7639 - val_accuracy: 0.8267\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.0725 - accuracy: 0.9779 - val_loss: 0.8079 - val_accuracy: 0.8267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yhu4ukiUTe3",
        "outputId": "dfb494d3-26d4-4bbc-d5d9-ce59b7ac1008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 7s - loss: 0.3550 - accuracy: 0.8454 - 7s/epoch - 4ms/step\n",
            "[0.3550426661968231, 0.8454136848449707]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -----\n",
        "# Mecab으로 토큰화 후 sentencepiece"
      ],
      "metadata": {
        "id": "JIexM9PnXPyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')"
      ],
      "metadata": {
        "id": "UL28dfiVy4qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
      ],
      "metadata": {
        "id": "B6wzCKsezAkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index:word for word, index in word_to_index.items()}"
      ],
      "metadata": {
        "id": "w817p275zAkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = get_decoded_sentences(X_train, index_to_word)"
      ],
      "metadata": {
        "id": "6szxen53zAke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (unigram(default), bpe, char, word)\n",
        "vs = 5000\n",
        "md = 'bpe'\n",
        "result_df = spm_write_and_tokenize(sen, 'naver', vocab_size = vs, model=md)"
      ],
      "metadata": {
        "id": "ubnSb3DRz_Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor, word_index, index_word = sp_tokenize(sp, train_data_t['document'])\n",
        "tensor_test, word_index_test, index_word_test = sp_tokenize(sp, test_data_t['document'])"
      ],
      "metadata": {
        "id": "xmMVfeGTz_Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "word_vector_dim = 32 # 2의 배수\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
        "model.add(keras.layers.LSTM(128))\n",
        "# model.add(keras.layers.LSTM(8, return_sequences = True))\n",
        "# model.add(keras.layers.LSTM(8, return_sequences = True))\n",
        "model.add(keras.layers.Dense(8, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad7a0fd-6f8a-4f9d-dc69-c28041cf57a4",
        "id": "R7lCVglOz_Eo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, None, 32)          160000    \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 128)               82432     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243,473\n",
            "Trainable params: 243,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_train[:50000]\n",
        "y_tr = y_train[50000:]\n",
        "X_val = tensor[:50000]\n",
        "X_train = tensor[50000:]\n",
        "\n",
        "X_test = tensor_test"
      ],
      "metadata": {
        "id": "GvZ-RVClz_Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "epochs= 100\n",
        "history = model.fit(X_train, y_tr, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), callbacks=[es], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c55f6c-a79a-4323-f8b4-fa36019f5abf",
        "id": "bfRqulbjz_Ep"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 [==============================] - 7s 29ms/step - loss: 0.5811 - accuracy: 0.7017 - val_loss: 0.4360 - val_accuracy: 0.7996\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3771 - accuracy: 0.8365 - val_loss: 0.3588 - val_accuracy: 0.8460\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3427 - accuracy: 0.8544 - val_loss: 0.3553 - val_accuracy: 0.8451\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3315 - accuracy: 0.8613 - val_loss: 0.3518 - val_accuracy: 0.8469\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3247 - accuracy: 0.8646 - val_loss: 0.3495 - val_accuracy: 0.8487\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3181 - accuracy: 0.8681 - val_loss: 0.3493 - val_accuracy: 0.8485\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.3097 - accuracy: 0.8723 - val_loss: 0.3484 - val_accuracy: 0.8485\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.2996 - accuracy: 0.8780 - val_loss: 0.3511 - val_accuracy: 0.8472\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.2889 - accuracy: 0.8823 - val_loss: 0.3574 - val_accuracy: 0.8491\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.2774 - accuracy: 0.8874 - val_loss: 0.3579 - val_accuracy: 0.8480\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.2675 - accuracy: 0.8921 - val_loss: 0.3644 - val_accuracy: 0.8455\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.2574 - accuracy: 0.8963 - val_loss: 0.3699 - val_accuracy: 0.8466\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.2471 - accuracy: 0.9011 - val_loss: 0.3887 - val_accuracy: 0.8458\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.2370 - accuracy: 0.9052 - val_loss: 0.3853 - val_accuracy: 0.8403\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.2249 - accuracy: 0.9108 - val_loss: 0.4000 - val_accuracy: 0.8426\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.2168 - accuracy: 0.9133 - val_loss: 0.4112 - val_accuracy: 0.8413\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.2074 - accuracy: 0.9175 - val_loss: 0.4431 - val_accuracy: 0.8386\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1986 - accuracy: 0.9199 - val_loss: 0.4471 - val_accuracy: 0.8382\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.1894 - accuracy: 0.9243 - val_loss: 0.4843 - val_accuracy: 0.8375\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1793 - accuracy: 0.9281 - val_loss: 0.5280 - val_accuracy: 0.8387\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.1710 - accuracy: 0.9312 - val_loss: 0.5219 - val_accuracy: 0.8329\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1636 - accuracy: 0.9336 - val_loss: 0.5481 - val_accuracy: 0.8308\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1536 - accuracy: 0.9377 - val_loss: 0.5803 - val_accuracy: 0.8264\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1452 - accuracy: 0.9397 - val_loss: 0.6167 - val_accuracy: 0.8284\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1385 - accuracy: 0.9426 - val_loss: 0.6371 - val_accuracy: 0.8257\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.1277 - accuracy: 0.9466 - val_loss: 0.7376 - val_accuracy: 0.8256\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - 5s 27ms/step - loss: 0.1202 - accuracy: 0.9496 - val_loss: 0.7532 - val_accuracy: 0.8247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3faa3a-579d-4c5a-8118-8e00adba976d",
        "id": "8DktVEb4z_Ep"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1537/1537 - 8s - loss: 0.3605 - accuracy: 0.8409 - 8s/epoch - 5ms/step\n",
            "[0.360478013753891, 0.8409178853034973]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaxfKJOZbPsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_p9srE9ubQAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36mJZtj42WBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}