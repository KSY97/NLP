{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def fun(x:str, y:float = 6.5)->int:\n",
        "  x = float(x)\n",
        "  return x+y\n",
        "value = fun('3')\n",
        "print(value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcY4GB4yGjt9",
        "outputId": "212e21f0-eae4-4bae-c840-2da186b92cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFKNnuV3DRHs",
        "outputId": "7c3ca242-309f-48e5-e647-59deb9768dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ1USDsBDWlT",
        "outputId": "0b7c19e7-19ec-498b-fb41-a38d1bc99728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: spacy\n",
            "Version: 3.4.1\n",
            "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
            "Home-page: https://spacy.io\n",
            "Author: Explosion\n",
            "Author-email: contact@explosion.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: pydantic, cymem, spacy-loggers, catalogue, tqdm, thinc, srsly, typing-extensions, requests, typer, pathy, langcodes, spacy-legacy, preshed, setuptools, packaging, jinja2, wasabi, murmurhash, numpy\n",
            "Required-by: fastai, en-core-web-sm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHjDrXiDNtV",
        "outputId": "37ad5b4d-fcaa-4f87-973b-7f69ffd2bb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-09-05 04:07:33.385539: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "text = \"David's book wasn't famous, but his family loved his book.\"\n",
        "for token in spacy_en.tokenizer(text):\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO_MMTT_Dg0d",
        "outputId": "bfc99c1c-d90e-4296-eaec-3e3433ac15fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "David\n",
            "'s\n",
            "book\n",
            "was\n",
            "n't\n",
            "famous\n",
            ",\n",
            "but\n",
            "his\n",
            "family\n",
            "loved\n",
            "his\n",
            "book\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet = u\"Snow White and the Seven Degrees #MakeAMovieCold@midnight:-)\"\n",
        "tokenizer = TweetTokenizer()\n",
        "print(tokenizer.tokenize(tweet.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gqRqylXF5PF",
        "outputId": "2605c84d-fab6-4f72-9f7c-4733ce522777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['snow', 'white', 'and', 'the', 'seven', 'degrees', '#makeamoviecold', '@midnight', ':-)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(\"Snow White and the Seven Degrees #MakeAMovieCold@midnight:-)\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMeGlw0AGNtF",
        "outputId": "26e3b221-6994-490f-bb9b-50e871e6690c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Snow', 'White', 'and', 'the', 'Seven', 'Degrees', '#', 'MakeAMovieCold', '@', 'midnight', ':', '-', ')']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, WordPunctTokenizer, TreebankWordTokenizer, RegexpTokenizer, sent_tokenize\n",
        "\n",
        "text = \"\"\"\n",
        "Have you ever fallen head.\n",
        "over heels for somebody.\n",
        "Not just somebody.\n",
        "No no.\n",
        "Rex you did it again.\n",
        "Have you ever fallen head.\n",
        "over heels for somebody.\n",
        "That made promises.\n",
        "to give you the world Um.\n",
        "I really hope they held you down.\n",
        "I really hope it was no lying.\n",
        "Cause when heart breaks it.\n",
        "feel like the world's gone.\n",
        "But if the love's real.\n",
        "\"\"\"\n",
        "\n",
        "print(word_tokenize(text))\n",
        "print(WordPunctTokenizer().tokenize(text))\n",
        "print(TreebankWordTokenizer().tokenize(text))\n",
        "print(RegexpTokenizer('\\w+').tokenize(text))\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfae8e73H5bO",
        "outputId": "98ee0d83-5938-4521-966e-0f0476872dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Have', 'you', 'ever', 'fallen', 'head', '.', 'over', 'heels', 'for', 'somebody', '.', 'Not', 'just', 'somebody', '.', 'No', 'no', '.', 'Rex', 'you', 'did', 'it', 'again', '.', 'Have', 'you', 'ever', 'fallen', 'head', '.', 'over', 'heels', 'for', 'somebody', '.', 'That', 'made', 'promises', '.', 'to', 'give', 'you', 'the', 'world', 'Um', '.', 'I', 'really', 'hope', 'they', 'held', 'you', 'down', '.', 'I', 'really', 'hope', 'it', 'was', 'no', 'lying', '.', 'Cause', 'when', 'heart', 'breaks', 'it', '.', 'feel', 'like', 'the', 'world', \"'s\", 'gone', '.', 'But', 'if', 'the', 'love', \"'s\", 'real', '.']\n",
            "['Have', 'you', 'ever', 'fallen', 'head', '.', 'over', 'heels', 'for', 'somebody', '.', 'Not', 'just', 'somebody', '.', 'No', 'no', '.', 'Rex', 'you', 'did', 'it', 'again', '.', 'Have', 'you', 'ever', 'fallen', 'head', '.', 'over', 'heels', 'for', 'somebody', '.', 'That', 'made', 'promises', '.', 'to', 'give', 'you', 'the', 'world', 'Um', '.', 'I', 'really', 'hope', 'they', 'held', 'you', 'down', '.', 'I', 'really', 'hope', 'it', 'was', 'no', 'lying', '.', 'Cause', 'when', 'heart', 'breaks', 'it', '.', 'feel', 'like', 'the', 'world', \"'\", 's', 'gone', '.', 'But', 'if', 'the', 'love', \"'\", 's', 'real', '.']\n",
            "['Have', 'you', 'ever', 'fallen', 'head.', 'over', 'heels', 'for', 'somebody.', 'Not', 'just', 'somebody.', 'No', 'no.', 'Rex', 'you', 'did', 'it', 'again.', 'Have', 'you', 'ever', 'fallen', 'head.', 'over', 'heels', 'for', 'somebody.', 'That', 'made', 'promises.', 'to', 'give', 'you', 'the', 'world', 'Um.', 'I', 'really', 'hope', 'they', 'held', 'you', 'down.', 'I', 'really', 'hope', 'it', 'was', 'no', 'lying.', 'Cause', 'when', 'heart', 'breaks', 'it.', 'feel', 'like', 'the', 'world', \"'s\", 'gone.', 'But', 'if', 'the', 'love', \"'s\", 'real', '.']\n",
            "['Have', 'you', 'ever', 'fallen', 'head', 'over', 'heels', 'for', 'somebody', 'Not', 'just', 'somebody', 'No', 'no', 'Rex', 'you', 'did', 'it', 'again', 'Have', 'you', 'ever', 'fallen', 'head', 'over', 'heels', 'for', 'somebody', 'That', 'made', 'promises', 'to', 'give', 'you', 'the', 'world', 'Um', 'I', 'really', 'hope', 'they', 'held', 'you', 'down', 'I', 'really', 'hope', 'it', 'was', 'no', 'lying', 'Cause', 'when', 'heart', 'breaks', 'it', 'feel', 'like', 'the', 'world', 's', 'gone', 'But', 'if', 'the', 'love', 's', 'real']\n",
            "['\\nHave you ever fallen head.', 'over heels for somebody.', 'Not just somebody.', 'No no.', 'Rex you did it again.', 'Have you ever fallen head.', 'over heels for somebody.', 'That made promises.', 'to give you the world Um.', 'I really hope they held you down.', 'I really hope it was no lying.', 'Cause when heart breaks it.', \"feel like the world's gone.\", \"But if the love's real.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "sentence = 'There is no royal road to learning'\n",
        "bigram = list(ngrams(sentence.split(), 2))\n",
        "print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWq5DAXJNWKw",
        "outputId": "31b921ab-4649-4ae3-b783-8e096e79ebe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'is'), ('is', 'no'), ('no', 'royal'), ('royal', 'road'), ('road', 'to'), ('to', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram = list(ngrams(sentence.split(), 3))\n",
        "print(trigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj6iCQr4NiO-",
        "outputId": "5179b61b-6fb1-49c3-99d3-3815ccb3a8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'is', 'no'), ('is', 'no', 'royal'), ('no', 'royal', 'road'), ('royal', 'road', 'to'), ('road', 'to', 'learning')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams(text,n):\n",
        "    '''\n",
        "    takes tokens or text, returns a list of n-grams\n",
        "    '''\n",
        "    return [text[i:i+n] for i in range(len(text)-n+1)]"
      ],
      "metadata": {
        "id": "bmRBnj0PNy5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = [\"mary\",\",\",\"n't\",\"slap\",\"green\",'witch',\".\"]\n",
        "print(n_grams(cleaned,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXXqWNT8N1GL",
        "outputId": "8bfb6017-d6d1-44ec-cdb4-3de8cc9fa709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "# 아래의 불용어는 저자가 임의로 선정한 것으로 실제 의미있는 선정 기준이 아님\n",
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"아무거나 아무렇게나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 하면 아니거든\"\n",
        "\n",
        "stop_words = set(stop_words.split(\" \"))\n",
        "word_tokens = word_tokenize(example)\n",
        "\n",
        "print(stop_words)\n",
        "\n",
        "result = [word for word in word_tokens if not word in stop_words]\n",
        "\n",
        "print(word_tokens) \n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4qWJbRJRVvQ",
        "outputId": "a1b5d7fa-5e4e-4ff7-e2a0-aaa3caa991c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'비슷하다', '이럴정도로', '어찌하든지', '아무거나', '하면', '예컨대', '같다', '아무렇게나', '아니거든'}\n",
            "['고기를', '아무렇게나', '구우려고', '하면', '안', '돼', '.', '고기라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n",
            "['고기를', '구우려고', '안', '돼', '.', '고기라고', '다', '같은', '게', '.', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex = '1 2 3 4 5 6 7 8 9 10'\n",
        "ex_t = set(ex.split(' '))\n",
        "# ex_t = {1, 2, 3, 4, 5, 8, 10, 6, 7, 9}\n",
        "# print(ex_t)\n",
        "# for i in ex_t:\n",
        "#   print(i)\n",
        "sorted(ex_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrYTCA8rRiwg",
        "outputId": "542fcb9f-3d91-46c3-cd41-1a30de3f63f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '10', '2', '3', '4', '5', '6', '7', '8', '9']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stemmer_f(idx):\n",
        "  from nltk.stem import PorterStemmer\n",
        "  stm = PorterStemmer()\n",
        "  return stm.stem(idx)"
      ],
      "metadata": {
        "id": "71zrEekyWBJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.stem import PorterStemmer\n",
        "# stemmer = PorterStemmer()\n",
        "\n",
        "# print(stemmer('working'))\n",
        "\n",
        "stemmer_f('working')\n",
        "\n",
        "# print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "# print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "# print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "# print(stemmer.stem('fancier'),stemmer.stem('fanciest'))\n",
        "# print(stemmer.stem('was'), stemmer.stem('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y28tjSXXVvSU",
        "outputId": "6d0b3bf7-54dc-4090-86c7-5616d0bc382d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'work'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))\n",
        "print(stemmer.stem('was'), stemmer.stem('love'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAMElySVVqd4",
        "outputId": "874ce124-ccac-4690-c7d1-97a8bcd259f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n",
            "was lov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.regexp import RegexpStemmer\n",
        "stm = RegexpStemmer('의')\n",
        "print(stm.stem('의사'))\n",
        "print(stm.stem('전문의사'))\n",
        "print(stm.stem('전문의'))\n",
        "print(stm.stem('시간의'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwh3UAz6ZuG7",
        "outputId": "596e160e-2b2b-4193-a64e-3dc20b1ac4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사\n",
            "전문사\n",
            "전문\n",
            "시간\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print([lemmatizer.lemmatize(w) for w in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjDjdpqx03Nz",
        "outputId": "80c8917d-8e12-4ead-ddd4-6263796b0ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r = re.compile('ab{2,}c')\n",
        "\n",
        "# r.search('ac')\n",
        "# r.search('abc')\n",
        "# r.search('abbc')\n",
        "r.search('abbbbbbbbbbbbbbbbbbbc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTC8kqRQ1Rfm",
        "outputId": "be747534-49e1-4f5b-99c0-0fda7d6f2f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 21), match='abbbbbbbbbbbbbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "Wx7qBr-h7AJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "metadata": {
        "id": "6M0sA4LT7Ek4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "text = sent_tokenize(text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxl3drMv7Fvr",
        "outputId": "9a26543f-4059-4bc9-d0d0-b132c1d549ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#정제와 단어 토큰화\n",
        "vocab = {} # 파이썬의 dictionary 자료형\n",
        "sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for i in text:\n",
        "    sentence = word_tokenize(i) # 단어 토큰화를 수행합니다.\n",
        "    result = []\n",
        "\n",
        "    for word in sentence: \n",
        "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄입니다.\n",
        "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거합니다.\n",
        "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거합니다.\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0 \n",
        "                vocab[word] += 1\n",
        "    sentences.append(result) \n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htn0lOe261rj",
        "outputId": "a62682a2-69e0-4b3c-d0aa-3c1f99a29f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAUSpsaa7I5l",
        "outputId": "f30dd81f-c8d0-49c7-96dc-3c33e14c3c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh6TPMHB7LvV",
        "outputId": "f7f04dbd-96ee-4b21-88cf-d308bc850df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = {}\n",
        "i = 0\n",
        "for word, freq in vocab_sorted :\n",
        "  if freq > 1:\n",
        "    i = i+1\n",
        "    word_to_idx[word] = i\n",
        "print(word_to_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0h_e05k7eb0",
        "outputId": "c6b0dd15-d0e4-45fa-bc01-70ec48a7000f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "words_freq = [w for w, c in word_to_idx.items() if c>= vocab_size +1]\n",
        "for w in words_freq:\n",
        "  del word_to_idx[w]\n",
        "print(word_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr1nFiJI78xJ",
        "outputId": "f1e18d11-2146-4654-aca7-8a1a45920cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx['OOV'] = len(word_to_idx) + 1\n",
        "print(len(word_to_idx))\n",
        "print(word_to_idx['OOV'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ-_T1br6mcu",
        "outputId": "40fbbd8b-6721-493f-9782-7e8d336f74db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = []\n",
        "for s in sentences:\n",
        "  # print('s : ', s)\n",
        "  temp = []\n",
        "  for w in s:\n",
        "    try:\n",
        "      temp.append(word_to_idx[w])\n",
        "    except KeyError:\n",
        "      temp.append(word_to_idx['OOV'])\n",
        "  encoded.append(temp)\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jJCTbEQ6sNP",
        "outputId": "f1e9c32e-07bd-43f5-9043-e00c02614922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "B9qYRkf2EE-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([4,5,6])"
      ],
      "metadata": {
        "id": "12TWYdUrEB5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack([a,b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TUzIK_9ELAT",
        "outputId": "c3984603-9087-4501-d375-323d81affb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzDjpY-fEMlI",
        "outputId": "fb3fe4ce-59dc-4737-f1c6-a7869482f740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.vstack([a,b])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1aeQkdNElL7",
        "outputId": "9325700e-99f3-4a10-8c80-f7d2c04fa305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# np.concatenate((a,b), axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "y93J7NJMEuRV",
        "outputId": "f90cdb0c-dc73-43be-b2e5-b8c9627ad743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-e65ed083a9da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array([[0, 1, 2], [3, 4, 5]])\n",
        "d = np.array([[6, 7, 8], [9, 10, 11]])\n",
        "\n",
        "np.concatenate((c, d), axis = 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBIXL3iGEzQn",
        "outputId": "768bfd9f-af62-4b08-9d5d-fa527d81ef90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  6,  7,  8],\n",
              "       [ 3,  4,  5,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.vstack([c,d])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTUrxN5_FNf7",
        "outputId": "366b4d7a-e38e-4ba8-e706-a70c4a0fb96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2],\n",
              "       [ 3,  4,  5],\n",
              "       [ 6,  7,  8],\n",
              "       [ 9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.column_stack([c,d])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvylRfz2HrLG",
        "outputId": "e68e3c31-e3f7-4d3f-f047-f5e82e1f3064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  6,  7,  8],\n",
              "       [ 3,  4,  5,  9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd = list(zip(c,d))\n",
        "print(cd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28uayN6aH7vp",
        "outputId": "ed708064-c42b-418a-a737-14ee2d9426e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(array([0, 1, 2]), array([6, 7, 8])), (array([3, 4, 5]), array([ 9, 10, 11]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = zip(['a', 1], ['b', 2], ['c', 3])\n",
        "print(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-13YjY-J-OX",
        "outputId": "e59a1e79-0500-4f5c-bade-83d80fbd7f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('a', 'b', 'c') (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(X,y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T31BFNc9KFeA",
        "outputId": "66e2938b-b438-4923-fb13-9fdf853706b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 1), ('b', 2), ('c', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "6fhY86S1Fz0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naVyT--rGrEB",
        "outputId": "d8715e65-f8d8-4005-d43c-4fd31ef39533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = sum(sentences, [])\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u0n3I3QGuw2",
        "outputId": "8b029200-1756-49c8-a286-d1d4b6f93c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter(words)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv-tSJTnG47C",
        "outputId": "25f674af-7867-4af0-ddfd-3498a6d89361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1x063MbHJpJ",
        "outputId": "3c1b1c10-3147-4512-e059-77043bdf7fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab:\n",
        "  i = i + 1\n",
        "  word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhQgM15OHRk0",
        "outputId": "557d16af-fe61-4d16-a178-6b1ff831c8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIh5jr6oQD5C",
        "outputId": "cddc8ecb-3711-4936-b288-2980fea0dd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Soi1PqukXnip",
        "outputId": "424a4fa9-5575-4258-ccbf-ee1e9520957f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(okt.pos('열심히 코딩한 당신, 연휴에는 여행을 가봐요'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm4gRZOMX19w",
        "outputId": "c4b71634-7727-4af8-ba65-eb0a04dc03d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(okt.nouns('열심히 코딩한 당신, 연휴에는 여행을 가봐요'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojZ3vQIhX9VF",
        "outputId": "53eee0cc-598b-4cc9-d4ca-172fb0dd5975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma  \n",
        "kkma=Kkma()  \n",
        "print(kkma.morphs(\"사과파이를 썬다\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIpENLkAYKeT",
        "outputId": "343af360-adb9-4eee-f015-0c9cbb2fa314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['사과', '파이', '를', '썰', 'ㄴ다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL8kioc8YMYC",
        "outputId": "ac34e109-a092-4631-b1b5-31669ef9bae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTe-LIocYSUp",
        "outputId": "782f9555-23b9-4eb0-bd36-92c2de1fa8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 14.14 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8kEDkjmZ9uT",
        "outputId": "8116e479-6f7c-4e16-ec2a-ee4bc565721e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2022-09-05 06:48:05--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.2, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLWYRFWIO&Signature=6GPRqDBp19WudJb%2Bakduga4sRN4%3D&x-amz-security-token=FwoGZXIvYXdzEFgaDDE5HTOsszm9TVgDwSK%2BAc4zC3iJbDQEf0ZLWrGHb1s2Yl9Ry0kxZw%2Fq97NZRz6g64TeCUg6TY9qIjF9O8ubN49Q6HOTz1RWMbCfg9CsFzXrv2BX63prE%2BDeiaoYFDWUlh5Xnb%2BLfcmv1i%2FC4BDnu1Xr2PYzo6hqizhMu43a1fwhjwzwUti%2BTtKzFCMFDVt0qxCcSO8P2TQhNCd%2F7j4A0S%2FEcMWe8P8es15av4xH462pMQhxKrFnSTBFk8gGwlKiqmG%2BHDGh4wVLnkSmlMIo7bTWmAYyLS4Ceb6p%2B3F4AbQ%2BBYy5IMZUaiAKy4cO6ZVvKZIWG4Y%2BXusEHi4eZY5D6LBOjg%3D%3D&Expires=1662361974 [following]\n",
            "--2022-09-05 06:48:05--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLWYRFWIO&Signature=6GPRqDBp19WudJb%2Bakduga4sRN4%3D&x-amz-security-token=FwoGZXIvYXdzEFgaDDE5HTOsszm9TVgDwSK%2BAc4zC3iJbDQEf0ZLWrGHb1s2Yl9Ry0kxZw%2Fq97NZRz6g64TeCUg6TY9qIjF9O8ubN49Q6HOTz1RWMbCfg9CsFzXrv2BX63prE%2BDeiaoYFDWUlh5Xnb%2BLfcmv1i%2FC4BDnu1Xr2PYzo6hqizhMu43a1fwhjwzwUti%2BTtKzFCMFDVt0qxCcSO8P2TQhNCd%2F7j4A0S%2FEcMWe8P8es15av4xH462pMQhxKrFnSTBFk8gGwlKiqmG%2BHDGh4wVLnkSmlMIo7bTWmAYyLS4Ceb6p%2B3F4AbQ%2BBYy5IMZUaiAKy4cO6ZVvKZIWG4Y%2BXusEHi4eZY5D6LBOjg%3D%3D&Expires=1662361974\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.11.134\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.11.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.12MB/s    in 0.4s    \n",
            "\n",
            "2022-09-05 06:48:06 (3.12 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2022-09-05 06:49:38--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLNFFQMFE&Signature=kCYe8jHLYypZLureXfTYP3U3cFI%3D&x-amz-security-token=FwoGZXIvYXdzEFgaDKhvnj1ASifXQBCAYSK%2BAfRxibCckfsSAZUM9Nd63B4HaE63fAmHo0KCwbyVfjnl%2FWFh5gvx62ztM2%2BHG1mJjCnyhSnE01Y2vIYOoPXqFTm88LWv7tZs2DQtjsrEhthKRKahGpNMPuQk6cral5GxLOeLs3egpYNBphwFo1G208bUW7aUaEbp93LkPfxlMyCqYNlSbnjvOO8LCJ6aGFGEy%2FkD2c9ICt6sV3q4gyngsFMU0THLA9a0noFQq6NE7ckaZ28%2BRSRXa09DI0vFbOso37LWmAYyLUqQuH4OTyCesGS47msMsXp8JVuLNlEzLp5ofKfTuD%2BXZh8nL07qA27KteWOWA%3D%3D&Expires=1662361703 [following]\n",
            "--2022-09-05 06:49:38--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLNFFQMFE&Signature=kCYe8jHLYypZLureXfTYP3U3cFI%3D&x-amz-security-token=FwoGZXIvYXdzEFgaDKhvnj1ASifXQBCAYSK%2BAfRxibCckfsSAZUM9Nd63B4HaE63fAmHo0KCwbyVfjnl%2FWFh5gvx62ztM2%2BHG1mJjCnyhSnE01Y2vIYOoPXqFTm88LWv7tZs2DQtjsrEhthKRKahGpNMPuQk6cral5GxLOeLs3egpYNBphwFo1G208bUW7aUaEbp93LkPfxlMyCqYNlSbnjvOO8LCJ6aGFGEy%2FkD2c9ICt6sV3q4gyngsFMU0THLA9a0noFQq6NE7ckaZ28%2BRSRXa09DI0vFbOso37LWmAYyLUqQuH4OTyCesGS47msMsXp8JVuLNlEzLp5ofKfTuD%2BXZh8nL07qA27KteWOWA%3D%3D&Expires=1662361703\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.224.121\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.224.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  98.8MB/s    in 0.5s    \n",
            "\n",
            "2022-09-05 06:49:39 (98.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab \n",
        "mecab = Mecab() \n",
        "text = u\"\"\"이제 구글 코랩에서 Mecab-ko라이브러리 사용이 가능합니다. 읽어주셔서 감사합니다.\"\"\" \n",
        "nouns = mecab.nouns(text) \n",
        "print(nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoaaCVNqZ-q8",
        "outputId": "07870d90-50ab-4f5b-d6a2-990545a8be44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['구글', '코', '랩', '라이브러리', '사용', '가능', '감사']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from konlpy.tag import Hannanum\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "hannanum = Hannanum()\n",
        "kkma = Kkma()\n",
        "okt = Okt()\n",
        "\n",
        "#예시를 위해 영문장, 한문장을 임의로 설정합니다.\n",
        "text1 = \"I am graduate Yonsei university. My major is Bio Medical engineering. but my favorite is Machine learning&Data Science.\"\n",
        "text2 = \"자연어 처리. 어렵네요. 특히 한국어 처리는 더 어려운거 같아요. 다들 화이팅하세요!\"\n",
        "\n",
        "print(\"sent_tokenize를 사용하면 아래와 같이 토큰화됩니다.\")\n",
        "print(sent_tokenize(text1))\n",
        "print(sent_tokenize(text2))\n",
        "\n",
        "print(\"Hannanum을 쓰면 아래와 같이 분류됩니다.\")\n",
        "print(hannanum.morphs(text1))\n",
        "print(hannanum.morphs(text2))\n",
        "\n",
        "print(\"Kkma를 쓰면 아래와 같이 분류됩니다.\")\n",
        "print(kkma.morphs(text1))\n",
        "print(kkma.morphs(text2))\n",
        "\n",
        "print(\"Okt를 사용하면 아래와 같이 분류됩니다.\")\n",
        "print(okt.morphs(text1))\n",
        "print(okt.morphs(text2))\n",
        "\n",
        "#jpype._jvmfinder.JVMNotFoundException: No JVM shared library file (jng>vm.dll) found. Try setting up the JAVA_HOME environment variable properly.\n",
        "#라는 오류가 발생하신다면 C:\\아나콘다설치위치\\Lib\\site-packages\\jpype 에 들어가서 _jvmfinder.py 파일을 여신 다음 ctrl + F 로 java_home 검색 후\n",
        "#java_home = \"자바설치경로\" 로 해주시면 오류없이 실행됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKvlElyefZi1",
        "outputId": "b36f16bf-acb3-482c-a3f7-4cc518509e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_tokenize를 사용하면 아래와 같이 토큰화됩니다.\n",
            "['I am graduate Yonsei university.', 'My major is Bio Medical engineering.', 'but my favorite is Machine learning&Data Science.']\n",
            "['자연어 처리.', '어렵네요.', '특히 한국어 처리는 더 어려운거 같아요.', '다들 화이팅하세요!']\n",
            "Hannanum을 쓰면 아래와 같이 분류됩니다.\n",
            "['I', 'am', 'graduate', 'Yonsei', 'university', '.', 'My', 'major', 'is', 'Bio', 'Medical', 'engineering', '.', 'but', 'my', 'favorite', 'is', 'Machine', 'learning&Data', 'Science', '.']\n",
            "['자연어', '처리', '.', '어렵', '네', '요', '.', '특히', '한국어', '처리', '는', '더', '어려운거', '같', '아', '요', '.', '다들', '화이팅하세요', '!']\n",
            "Kkma를 쓰면 아래와 같이 분류됩니다.\n",
            "['I', 'am', 'graduate', 'Yonsei', 'university', '.', 'My', 'major', 'is', 'Bio', 'Medical', 'engineering', '.', 'but', 'my', 'favorite', 'is', 'Machine', 'learning', '&', 'Data', 'Science', '.']\n",
            "['자연어', '처리', '.', '어렵', '네요', '.', '특히', '한국어', '처리', '는', '더', '어렵', 'ㄴ', '거', '같', '아요', '.', '다', '들', 'ㄹ', '화이팅하세', '요', '!']\n",
            "Okt를 사용하면 아래와 같이 분류됩니다.\n",
            "['I', 'am', 'graduate', 'Yonsei', 'university', '.', 'My', 'major', 'is', 'Bio', 'Medical', 'engineering', '.', 'but', 'my', 'favorite', 'is', 'Machine', 'learning', '&', 'Data', 'Science', '.']\n",
            "['자연어', '처리', '.', '어렵네요', '.', '특히', '한국어', '처리', '는', '더', '어려운거', '같아요', '.', '다', '들', '화이팅', '하세요', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import time\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Komoran\n",
        "from konlpy.tag import Kkma\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
        "\n",
        "\n",
        "def set_review_data(file_nm):\n",
        "    with open(file_nm, \"r\", encoding=\"utf8\") as f:\n",
        "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "    return data[1:20001]\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "print('[BEGIN] 리뷰 데이터를 읽는다.')\n",
        "review_data = set_review_data('ratings.txt')\n",
        "print('review_data size->', len(review_data))\n",
        "print('[END] 리뷰 데이터를 읽는다. (', time.time() - start_time, ')sec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnJkrqwhi4SD",
        "outputId": "ca1e9d7c-70f0-4aae-e8d7-439bee2ddf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BEGIN] 리뷰 데이터를 읽는다.\n",
            "review_data size-> 20000\n",
            "[END] 리뷰 데이터를 읽는다. ( 1.618776798248291 )sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kolnpy_perform = {}\n",
        "print(review_data[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s_eizgui4qo",
        "outputId": "79b4c617-b837-41a6-a746-308586e7f164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업이 부러웠는데. 사실 우리나라에서도 그 어려운시절에 끝까지 열정을 지킨 노라노 같은 전통이있어 저와 같은 사람들이 꿈을 꾸고 이뤄나갈 수 있다는 것에 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "kkma = Kkma()\n",
        "nouns = [kkma.nouns(datas[1]) for datas in review_data]\n",
        "print(nouns[1])\n",
        "kolnpy_perform['kkma'] = time.time() - start_time\n",
        "print('꼬꼬마 명사 추출 (', kolnpy_perform['kkma'], ')sec')"
      ],
      "metadata": {
        "id": "UnFrEQRhi8fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}